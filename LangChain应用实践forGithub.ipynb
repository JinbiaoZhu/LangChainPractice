{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48acba8c",
   "metadata": {},
   "source": [
    "### 通过 `!pip list` 检查必要的python依赖库是否都存在\n",
    "\n",
    "主要的两个python包是：\n",
    "\n",
    "openai                          0.27.8\n",
    "\n",
    "langchain                       0.0.200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23e3c711",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T05:32:20.334296Z",
     "start_time": "2023-06-28T05:32:19.874856Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                           Version\r\n",
      "--------------------------------- --------\r\n",
      "actionlib                         1.14.0\r\n",
      "aiohttp                           3.8.4\r\n",
      "aiosignal                         1.3.1\r\n",
      "angles                            1.9.13\r\n",
      "anyio                             3.7.0\r\n",
      "argilla                           1.11.0\r\n",
      "argon2-cffi                       21.3.0\r\n",
      "argon2-cffi-bindings              21.2.0\r\n",
      "arrow                             1.2.3\r\n",
      "asttokens                         2.2.1\r\n",
      "async-lru                         2.0.2\r\n",
      "async-timeout                     4.0.2\r\n",
      "attrs                             23.1.0\r\n",
      "Babel                             2.12.1\r\n",
      "backcall                          0.2.0\r\n",
      "backoff                           2.2.1\r\n",
      "beautifulsoup4                    4.12.2\r\n",
      "bleach                            6.0.0\r\n",
      "bondpy                            1.8.6\r\n",
      "camera-calibration                1.17.0\r\n",
      "camera-calibration-parsers        1.12.0\r\n",
      "catkin                            0.8.10\r\n",
      "certifi                           2023.5.7\r\n",
      "cffi                              1.15.1\r\n",
      "chardet                           5.1.0\r\n",
      "charset-normalizer                3.1.0\r\n",
      "chromadb                          0.3.26\r\n",
      "click                             8.1.3\r\n",
      "clickhouse-connect                0.6.4\r\n",
      "coloredlogs                       15.0.1\r\n",
      "comm                              0.1.3\r\n",
      "commonmark                        0.9.1\r\n",
      "controller-manager                0.19.6\r\n",
      "controller-manager-msgs           0.19.6\r\n",
      "cryptography                      41.0.1\r\n",
      "cv-bridge                         1.16.2\r\n",
      "dataclasses-json                  0.5.8\r\n",
      "debugpy                           1.6.7\r\n",
      "decorator                         5.1.1\r\n",
      "defusedxml                        0.7.1\r\n",
      "Deprecated                        1.2.14\r\n",
      "diagnostic-analysis               1.11.0\r\n",
      "diagnostic-common-diagnostics     1.11.0\r\n",
      "diagnostic-updater                1.11.0\r\n",
      "drone-wrapper                     1.4.2\r\n",
      "duckdb                            0.8.1\r\n",
      "dynamic-reconfigure               1.7.3\r\n",
      "et-xmlfile                        1.1.0\r\n",
      "exceptiongroup                    1.1.1\r\n",
      "executing                         1.2.0\r\n",
      "fastapi                           0.98.0\r\n",
      "fastjsonschema                    2.17.1\r\n",
      "filetype                          1.2.0\r\n",
      "flatbuffers                       23.5.26\r\n",
      "fqdn                              1.5.1\r\n",
      "frozenlist                        1.3.3\r\n",
      "gazebo_plugins                    2.9.2\r\n",
      "gazebo_ros                        2.9.2\r\n",
      "gencpp                            0.7.0\r\n",
      "geneus                            3.0.0\r\n",
      "genlisp                           0.4.18\r\n",
      "genmsg                            0.6.0\r\n",
      "gennodejs                         2.0.2\r\n",
      "genpy                             0.6.15\r\n",
      "google-search-results             2.4.2\r\n",
      "greenlet                          2.0.2\r\n",
      "h11                               0.14.0\r\n",
      "hnswlib                           0.7.0\r\n",
      "httpcore                          0.16.3\r\n",
      "httptools                         0.5.0\r\n",
      "httpx                             0.23.3\r\n",
      "humanfriendly                     10.0\r\n",
      "idna                              3.4\r\n",
      "image-geometry                    1.16.2\r\n",
      "interactive-markers               1.12.0\r\n",
      "ipykernel                         6.23.3\r\n",
      "ipython                           8.14.0\r\n",
      "ipython-genutils                  0.2.0\r\n",
      "isoduration                       20.11.0\r\n",
      "jedi                              0.18.2\r\n",
      "Jinja2                            3.1.2\r\n",
      "joblib                            1.2.0\r\n",
      "joint-state-publisher             1.15.1\r\n",
      "joint-state-publisher-gui         1.15.1\r\n",
      "json5                             0.9.14\r\n",
      "jsonpointer                       2.4\r\n",
      "jsonschema                        4.17.3\r\n",
      "jupyter_client                    8.3.0\r\n",
      "jupyter-contrib-core              0.4.2\r\n",
      "jupyter-contrib-nbextensions      0.7.0\r\n",
      "jupyter_core                      5.3.1\r\n",
      "jupyter-events                    0.6.3\r\n",
      "jupyter-highlight-selected-word   0.2.0\r\n",
      "jupyter-lsp                       2.2.0\r\n",
      "jupyter-nbextensions-configurator 0.6.3\r\n",
      "jupyter_server                    2.6.0\r\n",
      "jupyter_server_terminals          0.4.4\r\n",
      "jupyterlab                        4.0.2\r\n",
      "jupyterlab-pygments               0.2.2\r\n",
      "jupyterlab_server                 2.23.0\r\n",
      "langchain                         0.0.200\r\n",
      "langchainplus-sdk                 0.0.17\r\n",
      "laser_geometry                    1.6.7\r\n",
      "lxml                              4.9.2\r\n",
      "lz4                               4.3.2\r\n",
      "Markdown                          3.4.3\r\n",
      "markdown-it-py                    3.0.0\r\n",
      "MarkupSafe                        2.1.3\r\n",
      "marshmallow                       3.19.0\r\n",
      "marshmallow-enum                  1.5.1\r\n",
      "matplotlib-inline                 0.1.6\r\n",
      "mavros                            1.15.0\r\n",
      "mdurl                             0.1.2\r\n",
      "message-filters                   1.16.0\r\n",
      "mistune                           3.0.1\r\n",
      "monotonic                         1.6\r\n",
      "moveit-commander                  1.1.11\r\n",
      "moveit-core                       1.1.11\r\n",
      "moveit-python                     0.4.5\r\n",
      "moveit-ros-planning-interface     1.1.11\r\n",
      "moveit-ros-visualization          1.1.11\r\n",
      "moveit-task-constructor-core      0.1.3\r\n",
      "mpmath                            1.3.0\r\n",
      "msg-parser                        1.2.0\r\n",
      "multidict                         6.0.4\r\n",
      "mypy-extensions                   1.0.0\r\n",
      "nbclassic                         1.0.0\r\n",
      "nbclient                          0.8.0\r\n",
      "nbconvert                         7.6.0\r\n",
      "nbformat                          5.9.0\r\n",
      "nest-asyncio                      1.5.6\r\n",
      "nltk                              3.8.1\r\n",
      "notebook                          6.5.4\r\n",
      "notebook_shim                     0.2.3\r\n",
      "numexpr                           2.8.4\r\n",
      "numpy                             1.23.5\r\n",
      "olefile                           0.46\r\n",
      "onnxruntime                       1.15.1\r\n",
      "openai                            0.27.8\r\n",
      "openapi-schema-pydantic           1.2.4\r\n",
      "openpyxl                          3.1.2\r\n",
      "overrides                         7.3.1\r\n",
      "packaging                         23.1\r\n",
      "pandas                            1.5.3\r\n",
      "pandoc                            2.3\r\n",
      "pandocfilters                     1.5.0\r\n",
      "parso                             0.8.3\r\n",
      "pdf2image                         1.16.3\r\n",
      "pdfminer.six                      20221105\r\n",
      "pexpect                           4.8.0\r\n",
      "pickleshare                       0.7.5\r\n",
      "Pillow                            9.5.0\r\n",
      "pip                               23.1.2\r\n",
      "platformdirs                      3.8.0\r\n",
      "plumbum                           1.8.2\r\n",
      "ply                               3.11\r\n",
      "posthog                           3.0.1\r\n",
      "pr2_power_board                   1.1.10\r\n",
      "prometheus-client                 0.17.0\r\n",
      "prompt-toolkit                    3.0.38\r\n",
      "protobuf                          4.23.3\r\n",
      "psutil                            5.9.5\r\n",
      "ptyprocess                        0.7.0\r\n",
      "pulsar-client                     3.2.0\r\n",
      "pure-eval                         0.2.2\r\n",
      "py-trees                          0.7.6\r\n",
      "pycparser                         2.21\r\n",
      "pydantic                          1.10.9\r\n",
      "Pygments                          2.15.1\r\n",
      "pypandoc                          1.11\r\n",
      "pyrsistent                        0.19.3\r\n",
      "python-dateutil                   2.8.2\r\n",
      "python-docx                       0.8.11\r\n",
      "python-dotenv                     1.0.0\r\n",
      "python-json-logger                2.0.7\r\n",
      "python-magic                      0.4.27\r\n",
      "python-pptx                       0.6.21\r\n",
      "python-qt-binding                 0.4.4\r\n",
      "pytz                              2023.3\r\n",
      "PyYAML                            6.0\r\n",
      "pyzmq                             25.1.0\r\n",
      "qt-dotgraph                       0.4.2\r\n",
      "qt-gui                            0.4.2\r\n",
      "qt-gui-cpp                        0.4.2\r\n",
      "qt-gui-py-common                  0.4.2\r\n",
      "regex                             2023.6.3\r\n",
      "requests                          2.31.0\r\n",
      "resource_retriever                1.12.7\r\n",
      "rfc3339-validator                 0.1.4\r\n",
      "rfc3986                           1.5.0\r\n",
      "rfc3986-validator                 0.1.1\r\n",
      "rich                              13.0.1\r\n",
      "rosbag                            1.16.0\r\n",
      "rosboost-cfg                      1.15.8\r\n",
      "rosclean                          1.15.8\r\n",
      "roscreate                         1.15.8\r\n",
      "rosgraph                          1.16.0\r\n",
      "roslaunch                         1.16.0\r\n",
      "roslib                            1.15.8\r\n",
      "roslint                           0.12.0\r\n",
      "roslz4                            1.16.0\r\n",
      "rosmake                           1.15.8\r\n",
      "rosmaster                         1.16.0\r\n",
      "rosmsg                            1.16.0\r\n",
      "rosnode                           1.16.0\r\n",
      "rosparam                          1.16.0\r\n",
      "rospy                             1.16.0\r\n",
      "rosservice                        1.16.0\r\n",
      "rostest                           1.16.0\r\n",
      "rostopic                          1.16.0\r\n",
      "rosunit                           1.15.8\r\n",
      "roswtf                            1.16.0\r\n",
      "rqt_action                        0.4.9\r\n",
      "rqt_bag                           0.5.1\r\n",
      "rqt_bag_plugins                   0.5.1\r\n",
      "rqt_console                       0.4.11\r\n",
      "rqt-controller-manager            0.19.6\r\n",
      "rqt_dep                           0.4.12\r\n",
      "rqt-drone-teleop                  1.4.2\r\n",
      "rqt-ez-publisher                  0.6.1\r\n",
      "rqt_graph                         0.4.14\r\n",
      "rqt-ground-robot-teleop           1.4.2\r\n",
      "rqt_gui                           0.5.3\r\n",
      "rqt_gui_py                        0.5.3\r\n",
      "rqt-image-view                    0.4.17\r\n",
      "rqt_joint_trajectory_controller   0.21.1\r\n",
      "rqt_launch                        0.4.9\r\n",
      "rqt_logger_level                  0.4.11\r\n",
      "rqt-moveit                        0.5.10\r\n",
      "rqt_msg                           0.4.10\r\n",
      "rqt-multiplot                     0.0.12\r\n",
      "rqt_nav_view                      0.5.7\r\n",
      "rqt_plot                          0.4.13\r\n",
      "rqt_pose_view                     0.5.11\r\n",
      "rqt_pr2_dashboard                 0.4.0\r\n",
      "rqt_publisher                     0.4.10\r\n",
      "rqt_py_common                     0.5.3\r\n",
      "rqt_py_console                    0.4.10\r\n",
      "rqt_py_trees                      0.4.1\r\n",
      "rqt-reconfigure                   0.5.5\r\n",
      "rqt-robot-dashboard               0.5.8\r\n",
      "rqt-robot-monitor                 0.5.14\r\n",
      "rqt_robot_steering                0.5.12\r\n",
      "rqt_runtime_monitor               0.5.9\r\n",
      "rqt-rviz                          0.7.0\r\n",
      "rqt_service_caller                0.4.10\r\n",
      "rqt_shell                         0.4.11\r\n",
      "rqt_srv                           0.4.9\r\n",
      "rqt_tf_tree                       0.6.3\r\n",
      "rqt_top                           0.4.10\r\n",
      "rqt_topic                         0.4.13\r\n",
      "rqt_web                           0.4.10\r\n",
      "rviz                              1.14.20\r\n",
      "Send2Trash                        1.8.2\r\n",
      "sensor-msgs                       1.13.1\r\n",
      "setuptools                        67.8.0\r\n",
      "six                               1.16.0\r\n",
      "smach                             2.5.1\r\n",
      "smach-ros                         2.5.1\r\n",
      "smclib                            1.8.6\r\n",
      "sniffio                           1.3.0\r\n",
      "soupsieve                         2.4.1\r\n",
      "SQLAlchemy                        2.0.17\r\n",
      "srdfdom                           0.6.3\r\n",
      "stack-data                        0.6.2\r\n",
      "starlette                         0.27.0\r\n",
      "sympy                             1.12\r\n",
      "tabulate                          0.9.0\r\n",
      "tenacity                          8.2.2\r\n",
      "terminado                         0.17.1\r\n",
      "tf                                1.13.2\r\n",
      "tf-conversions                    1.13.2\r\n",
      "tf2-geometry-msgs                 0.7.6\r\n",
      "tf2-kdl                           0.7.6\r\n",
      "tf2-py                            0.7.6\r\n",
      "tf2-ros                           0.7.6\r\n",
      "tiktoken                          0.4.0\r\n",
      "tinycss2                          1.2.1\r\n",
      "tokenizers                        0.13.3\r\n",
      "tomli                             2.0.1\r\n",
      "topic-tools                       1.16.0\r\n",
      "tornado                           6.3.2\r\n",
      "tqdm                              4.65.0\r\n",
      "traitlets                         5.9.0\r\n",
      "typer                             0.9.0\r\n",
      "typing_extensions                 4.6.3\r\n",
      "typing-inspect                    0.9.0\r\n",
      "unique_id                         1.0.6\r\n",
      "unstructured                      0.7.9\r\n",
      "urdfdom-py                        0.4.6\r\n",
      "uri-template                      1.3.0\r\n",
      "urllib3                           2.0.3\r\n",
      "uvicorn                           0.22.0\r\n",
      "uvloop                            0.17.0\r\n",
      "watchfiles                        0.19.0\r\n",
      "wcwidth                           0.2.6\r\n",
      "webcolors                         1.13\r\n",
      "webencodings                      0.5.1\r\n",
      "websocket-client                  1.6.1\r\n",
      "websockets                        11.0.3\r\n",
      "wheel                             0.38.4\r\n",
      "wrapt                             1.14.1\r\n",
      "xacro                             1.14.15\r\n",
      "xlrd                              2.0.1\r\n",
      "XlsxWriter                        3.1.2\r\n",
      "yarl                              1.9.2\r\n",
      "youtube-transcript-api            0.6.1\r\n",
      "zstandard                         0.21.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8156ab11",
   "metadata": {},
   "source": [
    "### 导入python依赖库、类和函数方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9610f6dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T06:22:00.772466Z",
     "start_time": "2023-06-28T06:22:00.053245Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d711f9b",
   "metadata": {},
   "source": [
    "### 导入密钥（openai）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3b8a355",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T06:22:02.285394Z",
     "start_time": "2023-06-28T06:22:02.282827Z"
    }
   },
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = 'sk-your-openai-api-key'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fdd477",
   "metadata": {},
   "source": [
    "# <font color=red>项目1：构建最基本的文本对话</font>\n",
    "\n",
    " - 实例化一个大语言模型，这里实例化了 text-davinci-003 模型\n",
    " \n",
    " - 额外设置了参数 max_tokens=2048 ，其他参数按照类定义的默认值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfe20212",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T05:32:27.952464Z",
     "start_time": "2023-06-28T05:32:27.923299Z"
    }
   },
   "outputs": [],
   "source": [
    "BasicAskAnswer = OpenAI(model='text-davinci-003', max_tokens=2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3239afa0",
   "metadata": {},
   "source": [
    " - 接下来开始编写prompt提示词。\n",
    " \n",
    "> text-davinci-003 模型只能“一问一答”。如果需要能聊天的机器人，1）选用其他模型，例如 gpt-3.5-turbo；2）在prompt中增加上下文。\n",
    "\n",
    " - 最后输入到模型中等待回答。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4ac64af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T05:32:46.297690Z",
     "start_time": "2023-06-28T05:32:38.301981Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1. 鱼香肉丝：38元\\n2. 西红柿炒蛋：25元\\n3. 蒜蓉粉丝蒸排骨：48元\\n4. 宫保鸡丁：38元\\n5. 麻婆豆腐：32元\\n6. 糖醋排骨：45元\\n7. 茄子炒肉片：35元\\n8. 干锅鱼片：58元\\n9. 甜酸茄子拌豆腐：25元\\n10. 蔬菜拼盘：30元'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "            请你帮我设计一份中餐厅菜单。\\n\n",
    "            大概10种菜品，并设计出你的价格，以人民币为单位。\\n\n",
    "            请你以markdown语言格式化你的回答。\n",
    "         \"\"\"\n",
    "response = BasicAskAnswer(prompt=prompt)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ea43ad",
   "metadata": {},
   "source": [
    "在提示词中我们要求大语言模型输出 markdown 格式，但是纯 print 不好看。\n",
    "\n",
    "我们尝试使用 rich 库来辅助更漂亮的打印。\n",
    "\n",
    " - 先初始化一个虚拟控制台 csl ；\n",
    " - 讲原本是字符串的 response 转换成 markdown 实例\n",
    " - 将 markdown 实例输出到虚拟控制台 csl 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1be4e28b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T05:32:49.075913Z",
     "start_time": "2023-06-28T05:32:49.026429Z"
    }
   },
   "outputs": [],
   "source": [
    "import rich\n",
    "from rich.console import Console\n",
    "from rich.markdown import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f280904",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T05:32:51.328432Z",
     "start_time": "2023-06-28T05:32:51.323136Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  1 </span>鱼香肉丝：38元                                                                                                 \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  2 </span>西红柿炒蛋：25元                                                                                               \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  3 </span>蒜蓉粉丝蒸排骨：48元                                                                                           \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  4 </span>宫保鸡丁：38元                                                                                                 \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  5 </span>麻婆豆腐：32元                                                                                                 \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  6 </span>糖醋排骨：45元                                                                                                 \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  7 </span>茄子炒肉片：35元                                                                                               \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  8 </span>干锅鱼片：58元                                                                                                 \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  9 </span>甜酸茄子拌豆腐：25元                                                                                           \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 10 </span>蔬菜拼盘：30元                                                                                                 \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;33m  1 \u001b[0m鱼香肉丝：38元                                                                                                 \n",
       "\u001b[1;33m  2 \u001b[0m西红柿炒蛋：25元                                                                                               \n",
       "\u001b[1;33m  3 \u001b[0m蒜蓉粉丝蒸排骨：48元                                                                                           \n",
       "\u001b[1;33m  4 \u001b[0m宫保鸡丁：38元                                                                                                 \n",
       "\u001b[1;33m  5 \u001b[0m麻婆豆腐：32元                                                                                                 \n",
       "\u001b[1;33m  6 \u001b[0m糖醋排骨：45元                                                                                                 \n",
       "\u001b[1;33m  7 \u001b[0m茄子炒肉片：35元                                                                                               \n",
       "\u001b[1;33m  8 \u001b[0m干锅鱼片：58元                                                                                                 \n",
       "\u001b[1;33m  9 \u001b[0m甜酸茄子拌豆腐：25元                                                                                           \n",
       "\u001b[1;33m 10 \u001b[0m蔬菜拼盘：30元                                                                                                 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "csl = Console()\n",
    "md = Markdown(response)\n",
    "csl.print(md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9bff9f",
   "metadata": {},
   "source": [
    "# <font color=red>项目2：长文本总结</font>\n",
    "\n",
    " - 学习外源文本转变成输入模型提示词的过程。\n",
    " \n",
    " - 外源文本 $\\rightarrow$ 文档载入 $\\rightarrow$ 转成document对象 $\\rightarrow$ 文档切分 $\\rightarrow$ 向量数据库。\n",
    " \n",
    " - 文本内容和这个jupyter notebook在同级目录，便可以简便导入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5c20c09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T05:33:14.948397Z",
     "start_time": "2023-06-28T05:33:14.930431Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.summarize import load_summarize_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20ee15eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T05:33:24.836829Z",
     "start_time": "2023-06-28T05:33:24.834059Z"
    }
   },
   "outputs": [],
   "source": [
    "# 导入文本\n",
    "article_load = TextLoader(\"./content.txt\")\n",
    "# 转换成 document 对象\n",
    "article_document = article_load.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46876ec",
   "metadata": {},
   "source": [
    "这段代码创建了一个`RecursiveCharacterTextSplitter`对象，它是一个文本分割器，用于将长文本分割成较小的块。\n",
    "\n",
    "`chunk_size=500`指定了每个块的大小为500个字符。\n",
    "\n",
    "`chunk_overlap=0`指定了每个块之间没有重叠。\n",
    "\n",
    "`Recursive`表示该分割器可以递归地将块继续分割成更小的块。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ade38536",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T05:38:43.602163Z",
     "start_time": "2023-06-28T05:38:43.599858Z"
    }
   },
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca42208",
   "metadata": {},
   "source": [
    "接下来对文档进行切分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ab2584d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T05:38:44.807279Z",
     "start_time": "2023-06-28T05:38:44.803698Z"
    }
   },
   "outputs": [],
   "source": [
    "splitted_documents = text_splitter.split_documents(article_document)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3ffe2d",
   "metadata": {},
   "source": [
    "加载大语言模型，直接拿上面实例化的 `BasicAskAnswer` 大语言模型复制过来，得到实例 `TextSummarizerChain`，这里还是默认使用刚才的 text-davinci-003 模型。\n",
    "\n",
    "`refine`: 这种方式会先总结第一个 document，然后在将第一个 document 总结出的内容和第二个 document 一起发给 llm 模型在进行总结，以此类推。这种方式的好处就是在总结后一个 document 的时候，会带着前一个的 document 进行总结，给需要总结的 document 添加了上下文，增加了总结内容的连贯性。\n",
    "\n",
    "`verbose`：为 `True` 时候打印出模型的思考信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bfc68680",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T05:38:45.903075Z",
     "start_time": "2023-06-28T05:38:45.899276Z"
    }
   },
   "outputs": [],
   "source": [
    "TextSummarizer = BasicAskAnswer\n",
    "TextSummarizerChain = load_summarize_chain(llm=TextSummarizer, chain_type='refine', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a394403",
   "metadata": {},
   "source": [
    "把分割好的全部文本送入实例 `TextSummarizerChain` 。\n",
    "\n",
    "运行这个任务用了6分半，这可能是因为拆分文档的时候每一段分的太细了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd9676bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T05:39:52.869785Z",
     "start_time": "2023-06-28T05:38:48.112254Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"All neighborhoods are not created equal when it comes to air quality.\n",
      "\n",
      "Power plants, idling traffic, diesel trucks shipping goods and even the corner restaurant create different pollution signatures for different locations within cities and towns.\n",
      "\n",
      "This summer, experts from Northeastern University are embarking on a multi-year quest to come up with block-by-block air quality insights in Boston-area municipalities.\n",
      "\n",
      "The members of the interdisciplinary impact engine, known as iSUPER, will install more than 100 stationary pollution sensors in Brookline and Chelsea, and also explore Greater Boston streets in a van outfitted with monitoring equipment to detect greater variety of pollutants on a sub-neighborhood level. \n",
      "\n",
      "“Cities and towns have been making air pollution control decisions based on a few limited monitoring stations and regional averages,” says Yang Zhang, a Northeastern professor heading the iSUPER team.\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary\n",
      "We have provided an existing summary up to a certain point:  Northeastern University is launching a multi-year research project to collect block-by-block air quality data in the Greater Boston area in order to gain a better understanding of air quality and how it varies from neighborhood to neighborhood. The team will install 100 stationary sensors and explore areas in a van with monitoring equipment to detect a greater variety of pollutants. This data will help cities and towns make better informed decisions when it comes to air pollution control.\n",
      "We have the opportunity to refine the existing summary(only if needed) with some more context below.\n",
      "------------\n",
      "“Our focus is identifying hyperlocal hotspots, eventually in real time, to support strategies to reduce it or remove it,” she says.\n",
      "\n",
      "“I just feel we have this opportunity to do so much better in this area we know is critical for public health,” says team member and Northeastern assistant professor Amy Mueller, who is working with municipal officials and community groups to identify air quality concerns.\n",
      "\n",
      "So far the iSUPER team has overseen the installation of eight of the solar-powered sensors in Brookline and Chelsea in collaboration with the Massachusetts Department of Environmental Protection (DEP). \n",
      "\n",
      "Candidate locations for the rest of the sensor fleet are being identified through a collaborative process with municipal officials and community partners.\n",
      "------------\n",
      "Given the new context, refine the original summary\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary\n",
      "We have provided an existing summary up to a certain point: \n",
      "\n",
      "Northeastern University is launching a multi-year research project to collect block-by-block air quality data in the Greater Boston area in order to gain a better understanding of air quality and how it varies from neighborhood to neighborhood. The team, comprised of municipal officials and community groups, has already installed 8 of the 100 solar-powered sensors in Brookline and Chelsea in collaboration with the Massachusetts Department of Environmental Protection (DEP). The remaining sensors will be placed through a collaborative process with municipal officials and community partners to identify hyperlocal hotspots of air pollution. This data will help cities and towns make better informed decisions when it comes to air pollution control.\n",
      "We have the opportunity to refine the existing summary(only if needed) with some more context below.\n",
      "------------\n",
      "Team members will also hit the road in the Greater Boston area in a white van wrapped in the university logo. The vehicle is equipped with research-grade air quality instruments that can measure ultrafine particles and other types of pollution that stationary sensors cannot detect.\n",
      "\n",
      "“We plan to drive the vehicle in busy streets and several neighborhoods 10 to 20 times a day to better understand how things vary over time, an important thing for people to know in making decisions about their own activities,” Zhang says. \n",
      "\n",
      "The van, outfitted by a company run by Northeastern alumnus John Wilbur, arrived June 20, in time to study air quality impacts of the fireworks during the upcoming holiday.\n",
      "\n",
      "“July 4 is one national holiday I don’t want to miss because firework emissions contribute a lot to fine particulate concentrations (in the air),” Zhang says. “Oftentimes you see peak measurements three to five times higher than average.”\n",
      "------------\n",
      "Given the new context, refine the original summary\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary\n",
      "We have provided an existing summary up to a certain point: \n",
      "\n",
      "Northeastern University is launching a multi-year research project to collect block-by-block air quality data in the Greater Boston area in order to gain a better understanding of air quality and how it varies from neighborhood to neighborhood. The team, comprised of municipal officials and community groups, has already installed 8 of the 100 solar-powered sensors in Brookline and Chelsea in collaboration with the Massachusetts Department of Environmental Protection (DEP). The remaining sensors will be placed through a collaborative process with municipal officials and community partners to identify hyperlocal hotspots of air pollution, while the team will also hit the road in the Greater Boston area in a white van wrapped in the university logo. The vehicle is equipped with research-grade air quality instruments that can measure ultrafine particles and other types of pollution that stationary sensors cannot detect. This data will help cities and towns make better informed decisions when it comes to air pollution control, and the van will also be used to study air quality impacts of the fireworks during the upcoming holiday.\n",
      "We have the opportunity to refine the existing summary(only if needed) with some more context below.\n",
      "------------\n",
      "High levels of air pollution most affect children, the elderly and low-income individuals, causing an estimated 7 million premature deaths around the globe each year, according to the World Health Organization.\n",
      "\n",
      "Air pollution “increases the risk of respiratory infections, heart disease and lung cancer,” WHO says, adding that fine particulate matter that penetrates deep into lung passageways is most closely associated with “excessive premature mortality.”\n",
      "\n",
      "Mueller says the plan is for the iSUPER project to last at least five years, with the next activity after sensor installation being establishment of a data portal where communities can access and explore air quality measurements from the stationary sensors and mobile lab.\n",
      "------------\n",
      "Given the new context, refine the original summary\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary\n",
      "We have provided an existing summary up to a certain point: \n",
      "Northeastern University is launching a multi-year research project to collect block-by-block air quality data in the Greater Boston area in order to gain a better understanding of air quality and how it varies from neighborhood to neighborhood. The team, comprised of municipal officials and community groups, has already installed 8 of the 100 solar-powered sensors in Brookline and Chelsea in collaboration with the Massachusetts Department of Environmental Protection (DEP). The remaining sensors will be placed through a collaborative process with municipal officials and community partners to identify hyperlocal hotspots of air pollution, while the team will also hit the road in the Greater Boston area in a white van wrapped in the university logo. The vehicle is equipped with research-grade air quality instruments that can measure ultrafine particles and other types of pollution that stationary sensors cannot detect. This data will help cities and towns make better informed decisions when it comes to air pollution control, and the van will also be used to study air quality impacts of the fireworks during the upcoming holiday. High levels of air pollution, which can have severe health impacts on children, the elderly and low-income individuals, can be linked to an estimated 7 million premature deaths around the globe each year, according to the World Health Organization. The plan is for the iSUPER project to last at least five years, with the next activity after sensor installation being establishment of a data portal where communities can access and explore air quality measurements from the stationary sensors and mobile lab.\n",
      "We have the opportunity to refine the existing summary(only if needed) with some more context below.\n",
      "------------\n",
      "Figuring out how to convert the raw data into insightful information “is a big part of this project,” Mueller says. “Lots of times what we want to know isn’t just the measurement but also what it implies—what was the source?  How frequently does this affect people?  And most importantly—what might we be able to do to change things?”\n",
      "\n",
      "The impact engine team currently consists of 13 faculty members in a variety of disciplines, one staff member, two research technicians, one newly hired co-op student who will work with the town of Brookline, and 10 graduate students.\n",
      "\n",
      "The team will grow with four new faculty members, three new staff members, several postdoctoral researchers, and 10 more graduate students in the coming year, Zhang says.\n",
      "\n",
      "Erin Chute Gallentine, Brookline’s commissioner of public works, says that the partnership with Northeastern will allow the town to try new approaches to air quality technology, practices and management.\n",
      "------------\n",
      "Given the new context, refine the original summary\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary\n",
      "We have provided an existing summary up to a certain point: \n",
      "Northeastern University is launching a multi-year research project to collect block-by-block air quality data in the Greater Boston area in order to gain a better understanding of air quality and how it varies from neighborhood to neighborhood. The team is comprised of municipal officials and community groups, and has already installed 8 of the 100 solar-powered sensors in Brookline and Chelsea in collaboration with the Massachusetts Department of Environmental Protection (DEP). The remaining sensors will be placed through a collaborative process with municipal officials and community partners to identify hyperlocal hotspots of air pollution. The impact engine team currently consists of 13 faculty members in a variety of disciplines, one staff member, two research technicians, one co-op student, and 10 graduate students. The team will also hit the road in the Greater Boston area in a white van wrapped in the university logo, which is equipped with research-grade air quality instruments that can measure ultrafine particles and other types of pollution that stationary sensors cannot detect. The data collected will help cities and towns make better informed decisions when it comes to air pollution control, and the van will also be used to study air quality impacts of the fireworks during the upcoming holiday. The plan is for the iSUPER project to last at least five years, with the next activity after sensor installation being establishment of a data portal where communities can access and explore air quality measurements from the stationary sensors and mobile lab. The project will also involve translating the raw data into insightful information, and will be staffed by four new faculty members, three new staff members, several postdoctoral researchers, and 10 more graduate students in the coming year. This partnership with Northeastern will also allow the town to try new approaches to air quality technology, practices and management, and has the potential to save millions of lives around the globe, as high levels of air pollution can have severe health impacts on children, the elderly and low-income individuals.\n",
      "We have the opportunity to refine the existing summary(only if needed) with some more context below.\n",
      "------------\n",
      "“It’s an exciting opportunity to understand air quality and impacts of air quality not only in Brookline but throughout the region,” she says.\n",
      "\n",
      "Zhang says the plan is to eventually expand the iSUPER project—short for Intelligent Solutions to Urban Pollution for Equity and Resilience—to additional locations.\n",
      "\n",
      "Figuring out how to convert the raw data into insightful information “is a big part of this project,” Mueller says. “Lots of times what we want to know isn’t just the measurement but also what it implies—what was the source?  How frequently does this affect people?  And most importantly—what might we be able to do to change things?”\n",
      "\n",
      "The impact engine team currently consists of 13 faculty members in a variety of disciplines, one staff member, two research technicians, one newly hired co-op student who will work with the town of Brookline, and 10 graduate students.\n",
      "------------\n",
      "Given the new context, refine the original summary\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary\n",
      "We have provided an existing summary up to a certain point: \n",
      "Northeastern University is launching a multi-year research project, iSUPER (Intelligent Solutions to Urban Pollution for Equity and Resilience), to collect block-by-block air quality data in the Greater Boston area. The team is comprised of municipal officials, community groups, 13 faculty members from a variety of disciplines, one staff member, two research technicians, one co-op student, and 10 graduate students. The team has already installed 8 of the 100 solar-powered sensors in Brookline and Chelsea in collaboration with the Massachusetts Department of Environmental Protection (DEP). The remaining sensors will be placed through a collaborative process with municipal officials and community partners to identify hyperlocal hotspots of air pollution. The project aims to establish a data portal where communities can access and explore air quality measurements from the stationary sensors and mobile lab, and to translate the raw data into insightful information. The van, wrapped in the university logo, will be equipped with research-grade air quality instruments that can measure ultrafine particles and other types of pollution that stationary sensors cannot detect. This partnership with Northeastern has the potential to save millions of lives around the globe, as high levels of air pollution can have severe health impacts on children, the elderly and low-income individuals.\n",
      "We have the opportunity to refine the existing summary(only if needed) with some more context below.\n",
      "------------\n",
      "The team will grow with four new faculty members, three new staff members, several postdoctoral researchers, and 10 more graduate students in the coming year, Zhang says.\n",
      "\n",
      "Erin Chute Gallentine, Brookline’s commissioner of public works, says that the partnership with Northeastern will allow the town to try new approaches to air quality technology, practices and management.\n",
      "\n",
      "“It’s an exciting opportunity to understand air quality and impacts of air quality not only in Brookline but throughout the region,” she says.\n",
      "\n",
      "Zhang says the plan is to eventually expand the iSUPER project—short for Intelligent Solutions to Urban Pollution for Equity and Resilience—to additional locations.\n",
      "\n",
      "A neighborhood that has a power plant or is downwind from one, for instance, might have higher levels of nitrogen oxide and sulfur dioxide than other locations within a city, she says.\n",
      "------------\n",
      "Given the new context, refine the original summary\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary\n",
      "We have provided an existing summary up to a certain point: \n",
      "\n",
      "Northeastern University is launching a multi-year research project, iSUPER (Intelligent Solutions to Urban Pollution for Equity and Resilience), to collect block-by-block air quality data in the Greater Boston area. The team is comprised of municipal officials, community groups, 13 faculty members from a variety of disciplines, one staff member, two research technicians, one co-op student, and 10 graduate students. The team will grow with four new faculty members, three new staff members, several postdoctoral researchers, and 10 more graduate students in the coming year. The team has already installed 8 of the 100 solar-powered sensors in Brookline and Chelsea in collaboration with the Massachusetts Department of Environmental Protection (DEP) and plan to expand the project to additional locations. The project aims to establish a data portal where communities can access and explore air quality measurements from the stationary sensors and mobile lab, and to translate the raw data into insightful information. The van, wrapped in the university logo, will be equipped with research-grade air quality instruments that can measure ultrafine particles and other types of pollution that stationary sensors cannot detect. This partnership with Northeastern has the potential to save millions of lives around the globe, as high levels of air pollution can have severe health impacts on children, the elderly and low-income individuals.\n",
      "We have the opportunity to refine the existing summary(only if needed) with some more context below.\n",
      "------------\n",
      "Even restaurant ventilation systems can affect local air quality by particles and volatile organic compounds, especially from cooking meat, Zhang says.\n",
      "\n",
      "“Recent studies show that air pollution levels could vary by five to eight times across a city block,” she says.\n",
      "\n",
      "“There’s a fundamental lack of hyperlocal data for city level decisions,” Zhang says. “Our goal for the impact engine is to address those key gaps in understanding and build tools to help us integrate air quality into all city design processes.”\n",
      "\n",
      "Mueller says the information could help with city planning on multiple levels.\n",
      "\n",
      "“What are the impacts when we redesign our roads to add bike or bus or dedicated turning lanes?  What are the impacts of adding green spaces?” she says. “How do we think about air quality impacts of new (especially very tall) buildings that can create urban canyons in the city?”\n",
      "------------\n",
      "Given the new context, refine the original summary\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nNortheastern University is launching a multi-year research project, iSUPER (Intelligent Solutions to Urban Pollution for Equity and Resilience), to collect block-by-block air quality data in the Greater Boston area. The team is comprised of municipal officials, community groups, 13 faculty members from a variety of disciplines, one staff member, two research technicians, one co-op student, and 10 graduate students. It is set to expand with four new faculty members, three new staff members, several postdoctoral researchers, and 10 more graduate students in the coming year. The team has already installed 8 of the 100 solar-powered sensors in Brookline and Chelsea in collaboration with the Massachusetts Department of Environmental Protection (DEP), and plan to expand the project to additional locations. The project aims to establish a data portal where communities can access and explore air quality measurements from the stationary sensors and mobile lab, and to translate the raw data into insightful information. The van, wrapped in the university logo, will be equipped with research-grade air quality instruments that can measure ultrafine particles and other types of pollution that stationary sensors cannot detect. This partnership with Northeastern has the potential to save millions of lives around the globe, as high levels of air pollution can have severe health impacts on children, the elderly and low-income individuals. The information could also help with city planning on multiple levels, such as understanding the impacts of adding green spaces, bike/bus lanes, and very tall buildings. Even restaurant ventilation systems can affect local air quality, and recent studies have shown that air pollution levels could vary by five to eight times across a city block. The project aims to address these key gaps in understanding and build tools to help integrate air quality into all city design processes.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = TextSummarizerChain.run(splitted_documents[:])\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229aa87d",
   "metadata": {},
   "source": [
    "同样地，用 rich 的 markdown 打印出来～\n",
    "\n",
    "可以看到，用 text-davinci-003 和 load_summarize_chain 可以实现很长文档的总结！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "faa95f95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T05:40:05.455729Z",
     "start_time": "2023-06-28T05:40:05.450592Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Northeastern University is launching a multi-year research project, iSUPER (Intelligent Solutions to Urban         \n",
       "Pollution for Equity and Resilience), to collect block-by-block air quality data in the Greater Boston area. The   \n",
       "team is comprised of municipal officials, community groups, 13 faculty members from a variety of disciplines, one  \n",
       "staff member, two research technicians, one co-op student, and 10 graduate students. It is set to expand with four \n",
       "new faculty members, three new staff members, several postdoctoral researchers, and 10 more graduate students in   \n",
       "the coming year. The team has already installed 8 of the 100 solar-powered sensors in Brookline and Chelsea in     \n",
       "collaboration with the Massachusetts Department of Environmental Protection (DEP), and plan to expand the project  \n",
       "to additional locations. The project aims to establish a data portal where communities can access and explore air  \n",
       "quality measurements from the stationary sensors and mobile lab, and to translate the raw data into insightful     \n",
       "information. The van, wrapped in the university logo, will be equipped with research-grade air quality instruments \n",
       "that can measure ultrafine particles and other types of pollution that stationary sensors cannot detect. This      \n",
       "partnership with Northeastern has the potential to save millions of lives around the globe, as high levels of air  \n",
       "pollution can have severe health impacts on children, the elderly and low-income individuals. The information could\n",
       "also help with city planning on multiple levels, such as understanding the impacts of adding green spaces, bike/bus\n",
       "lanes, and very tall buildings. Even restaurant ventilation systems can affect local air quality, and recent       \n",
       "studies have shown that air pollution levels could vary by five to eight times across a city block. The project    \n",
       "aims to address these key gaps in understanding and build tools to help integrate air quality into all city design \n",
       "processes.                                                                                                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Northeastern University is launching a multi-year research project, iSUPER (Intelligent Solutions to Urban         \n",
       "Pollution for Equity and Resilience), to collect block-by-block air quality data in the Greater Boston area. The   \n",
       "team is comprised of municipal officials, community groups, 13 faculty members from a variety of disciplines, one  \n",
       "staff member, two research technicians, one co-op student, and 10 graduate students. It is set to expand with four \n",
       "new faculty members, three new staff members, several postdoctoral researchers, and 10 more graduate students in   \n",
       "the coming year. The team has already installed 8 of the 100 solar-powered sensors in Brookline and Chelsea in     \n",
       "collaboration with the Massachusetts Department of Environmental Protection (DEP), and plan to expand the project  \n",
       "to additional locations. The project aims to establish a data portal where communities can access and explore air  \n",
       "quality measurements from the stationary sensors and mobile lab, and to translate the raw data into insightful     \n",
       "information. The van, wrapped in the university logo, will be equipped with research-grade air quality instruments \n",
       "that can measure ultrafine particles and other types of pollution that stationary sensors cannot detect. This      \n",
       "partnership with Northeastern has the potential to save millions of lives around the globe, as high levels of air  \n",
       "pollution can have severe health impacts on children, the elderly and low-income individuals. The information could\n",
       "also help with city planning on multiple levels, such as understanding the impacts of adding green spaces, bike/bus\n",
       "lanes, and very tall buildings. Even restaurant ventilation systems can affect local air quality, and recent       \n",
       "studies have shown that air pollution levels could vary by five to eight times across a city block. The project    \n",
       "aims to address these key gaps in understanding and build tools to help integrate air quality into all city design \n",
       "processes.                                                                                                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "md = Markdown(response)\n",
    "csl.print(md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83228af",
   "metadata": {},
   "source": [
    "# <font color=red>项目3：基于Google的搜索问答</font>\n",
    "\n",
    "- 进行Google搜索需要使用Google提供的API接口。\n",
    "\n",
    "  教程如下：首先需要我们到 Serpapi 官网上注册一个用户，https://serpapi.com/ 并复制他给我们生成 api key。\n",
    "\n",
    "- 一些主要库和对应版本列表如下：\n",
    "\n",
    "  `google-search-results` ==2.4.2\n",
    "  \n",
    "- 安装一下必要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c42ff84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T05:40:22.240740Z",
     "start_time": "2023-06-28T05:40:21.322286Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-search-results==2.4.2 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (2.4.2)\r\n",
      "Requirement already satisfied: requests in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from google-search-results==2.4.2) (2.31.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from requests->google-search-results==2.4.2) (3.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from requests->google-search-results==2.4.2) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from requests->google-search-results==2.4.2) (2.0.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from requests->google-search-results==2.4.2) (2023.5.7)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install google-search-results==2.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe112c90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T05:40:26.432327Z",
     "start_time": "2023-06-28T05:40:26.428669Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent, load_tools, AgentType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2476bb7f",
   "metadata": {},
   "source": [
    "导入能使用的 Google 搜索的 api 密钥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48a9e759",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T06:22:26.059050Z",
     "start_time": "2023-06-28T06:22:26.056429Z"
    }
   },
   "outputs": [],
   "source": [
    "os.environ['SERPAPI_API_KEY'] = 'your-serpapi-api-key'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425def39",
   "metadata": {},
   "source": [
    "加载大语言模型，直接拿上面实例化的 `BasicAskAnswer` 大语言模型复制过来，得到实例 `SearchGoogle`，这里还是默认使用刚才的 text-davinci-003 模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ada5300f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T05:40:36.182347Z",
     "start_time": "2023-06-28T05:40:36.179034Z"
    }
   },
   "outputs": [],
   "source": [
    "SearchGoogle = BasicAskAnswer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec7c550",
   "metadata": {},
   "source": [
    "因为基于Google的搜索回答很有可能是超出训练数据集外的。因此这里使用 langchain 的 agent ，让他根据设置好的 tool 来执行任务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0b618be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T05:43:04.797445Z",
     "start_time": "2023-06-28T05:43:04.795096Z"
    }
   },
   "outputs": [],
   "source": [
    "tools = load_tools(['serpapi'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4c3788",
   "metadata": {},
   "source": [
    "实例化智能体，把大语言模型、工具还有智能体类型都加进去做初始化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "47803c59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T05:43:06.248282Z",
     "start_time": "2023-06-28T05:43:06.244015Z"
    }
   },
   "outputs": [],
   "source": [
    "agent = initialize_agent(llm=SearchGoogle, tools=tools, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cb26ce",
   "metadata": {},
   "source": [
    "可见，基于Google的问答系统，可以获取到最新的国家的新闻。当然，你的prompt提示词要尽可能完善。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "438d8df3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T05:43:40.397131Z",
     "start_time": "2023-06-28T05:43:29.310887Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m 我需要搜索来获得一个准确的定义\n",
      "Action: Search\n",
      "Action Input: 贸易顺差\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m所谓贸易顺差是指在特定年度一国出口贸易总额大于进口贸易总额，又称“出超”。 贸易顺差就是在一定的单位时间里（通常按年度计算），贸易的双方互相买卖各种货物，互相进口与出口，甲方的出口金额大过乙方的出口金额，或甲方的进口金额少于乙方的进口金额，其中的差额，对甲方来说，就叫作贸易顺差，反之，对乙方来说，就叫作贸易逆差。\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m 现在我知道答案了\n",
      "Final Answer: 贸易顺差是指在特定年度一国出口贸易总额大于进口贸易总额，又称“出超”，其中的差额，对甲方来说，就叫作贸易顺差，反之，对乙方来说，就叫作贸易逆差。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'贸易顺差是指在特定年度一国出口贸易总额大于进口贸易总额，又称“出超”，其中的差额，对甲方来说，就叫作贸易顺差，反之，对乙方来说，就叫作贸易逆差。'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = agent.run(\"什么是贸易顺差？\")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944899d2",
   "metadata": {},
   "source": [
    "关于agent type 几个选项的含义：\n",
    "\n",
    "`zero-shot-react-description`: 根据工具的描述和请求内容的来决定使用哪个工具（最常用）\n",
    "\n",
    "`react-docstore`: 使用 ReAct 框架和 docstore 交互, 使用 `Search` 和 `Lookup` 工具, 前者用来搜, 后者寻找term, 举例: `Wipipedia` 工具\n",
    "\n",
    "`self-ask-with-search`: 此智能体只使用一个工具: Intermediate Answer, 它会为问题寻找事实答案(指的非 gpt 生成的答案, 而是在网络中,文本中已存在的), 如 `Google search API` 工具\n",
    "\n",
    "`conversational-react-description`: 为会话设置而设计的智能体, 它的prompt会被设计的具有会话性, 且还是会使用 ReAct 框架来决定使用来个工具, 并且将过往的会话交互存入内存"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafd55fc",
   "metadata": {},
   "source": [
    "# <font color=red>项目4：基于本地知识库的问答机器人</font>\n",
    "\n",
    "如何从我们本地读取多个文档构建知识库，并且使用 Openai API 在知识库中进行搜索并给出答案。\n",
    "\n",
    "首先，导入一些必要依赖项。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0a0828ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T05:44:35.053530Z",
     "start_time": "2023-06-28T05:44:32.061769Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unstructured in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (0.7.9)\n",
      "Requirement already satisfied: argilla in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from unstructured) (1.11.0)\n",
      "Requirement already satisfied: chardet in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from unstructured) (5.1.0)\n",
      "Requirement already satisfied: filetype in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from unstructured) (1.2.0)\n",
      "Requirement already satisfied: lxml in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from unstructured) (4.9.2)\n",
      "Requirement already satisfied: msg-parser in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from unstructured) (1.2.0)\n",
      "Requirement already satisfied: nltk in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from unstructured) (3.8.1)\n",
      "Requirement already satisfied: openpyxl in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from unstructured) (3.1.2)\n",
      "Requirement already satisfied: pandas in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from unstructured) (1.5.3)\n",
      "Requirement already satisfied: pdf2image in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from unstructured) (1.16.3)\n",
      "Requirement already satisfied: pdfminer.six in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from unstructured) (20221105)\n",
      "Requirement already satisfied: pillow in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from unstructured) (9.5.0)\n",
      "Requirement already satisfied: pypandoc in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from unstructured) (1.11)\n",
      "Requirement already satisfied: python-docx in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from unstructured) (0.8.11)\n",
      "Requirement already satisfied: python-pptx in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from unstructured) (0.6.21)\n",
      "Requirement already satisfied: python-magic in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from unstructured) (0.4.27)\n",
      "Requirement already satisfied: markdown in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from unstructured) (3.4.3)\n",
      "Requirement already satisfied: requests in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from unstructured) (2.31.0)\n",
      "Requirement already satisfied: tabulate in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from unstructured) (0.9.0)\n",
      "Requirement already satisfied: xlrd in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from unstructured) (2.0.1)\n",
      "Requirement already satisfied: httpx<0.24,>=0.15 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from argilla->unstructured) (0.23.3)\n",
      "Requirement already satisfied: deprecated~=1.2.0 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from argilla->unstructured) (1.2.14)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from argilla->unstructured) (23.1)\n",
      "Requirement already satisfied: pydantic>=1.10.7 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from argilla->unstructured) (1.10.9)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.13 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from argilla->unstructured) (1.14.1)\n",
      "Requirement already satisfied: numpy<1.24.0 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from argilla->unstructured) (1.23.5)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from argilla->unstructured) (4.65.0)\n",
      "Requirement already satisfied: backoff in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from argilla->unstructured) (2.2.1)\n",
      "Requirement already satisfied: monotonic in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from argilla->unstructured) (1.6)\n",
      "Requirement already satisfied: rich<=13.0.1 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from argilla->unstructured) (13.0.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.6.0 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from argilla->unstructured) (0.9.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from pandas->unstructured) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from pandas->unstructured) (2023.3)\n",
      "Requirement already satisfied: olefile>=0.46 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from msg-parser->unstructured) (0.46)\n",
      "Requirement already satisfied: click in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from nltk->unstructured) (8.1.3)\n",
      "Requirement already satisfied: joblib in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from nltk->unstructured) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from nltk->unstructured) (2023.6.3)\n",
      "Requirement already satisfied: et-xmlfile in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from openpyxl->unstructured) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from pdfminer.six->unstructured) (3.1.0)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from pdfminer.six->unstructured) (41.0.1)\n",
      "Requirement already satisfied: XlsxWriter>=0.5.7 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from python-pptx->unstructured) (3.1.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from requests->unstructured) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from requests->unstructured) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from requests->unstructured) (2023.5.7)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from cryptography>=36.0.0->pdfminer.six->unstructured) (1.15.1)\n",
      "Requirement already satisfied: httpcore<0.17.0,>=0.15.0 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from httpx<0.24,>=0.15->argilla->unstructured) (0.16.3)\n",
      "Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from httpx<0.24,>=0.15->argilla->unstructured) (1.5.0)\n",
      "Requirement already satisfied: sniffio in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from httpx<0.24,>=0.15->argilla->unstructured) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from pydantic>=1.10.7->argilla->unstructured) (4.6.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->unstructured) (1.16.0)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from rich<=13.0.1->argilla->unstructured) (0.9.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from rich<=13.0.1->argilla->unstructured) (2.15.1)\n",
      "Requirement already satisfied: pycparser in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->unstructured) (2.21)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from httpcore<0.17.0,>=0.15.0->httpx<0.24,>=0.15->argilla->unstructured) (0.14.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from httpcore<0.17.0,>=0.15.0->httpx<0.24,>=0.15->argilla->unstructured) (3.7.0)\n",
      "Requirement already satisfied: exceptiongroup in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from anyio<5.0,>=3.0->httpcore<0.17.0,>=0.15.0->httpx<0.24,>=0.15->argilla->unstructured) (1.1.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chromadb in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (0.3.26)\n",
      "Requirement already satisfied: pandas>=1.3 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from chromadb) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.28 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from chromadb) (2.31.0)\n",
      "Requirement already satisfied: pydantic>=1.9 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from chromadb) (1.10.9)\n",
      "Requirement already satisfied: hnswlib>=0.7 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from chromadb) (0.7.0)\n",
      "Requirement already satisfied: clickhouse-connect>=0.5.7 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from chromadb) (0.6.4)\n",
      "Requirement already satisfied: duckdb>=0.7.1 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from chromadb) (0.8.1)\n",
      "Requirement already satisfied: fastapi>=0.85.1 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from chromadb) (0.98.0)\n",
      "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from chromadb) (0.22.0)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from chromadb) (1.23.5)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from chromadb) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from chromadb) (4.6.3)\n",
      "Requirement already satisfied: pulsar-client>=3.1.0 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from chromadb) (3.2.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from chromadb) (1.15.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from chromadb) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from chromadb) (4.65.0)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from chromadb) (7.3.1)\n",
      "Requirement already satisfied: certifi in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from clickhouse-connect>=0.5.7->chromadb) (2023.5.7)\n",
      "Requirement already satisfied: urllib3>=1.26 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from clickhouse-connect>=0.5.7->chromadb) (2.0.3)\n",
      "Requirement already satisfied: pytz in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from clickhouse-connect>=0.5.7->chromadb) (2023.3)\n",
      "Requirement already satisfied: zstandard in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from clickhouse-connect>=0.5.7->chromadb) (0.21.0)\n",
      "Requirement already satisfied: lz4 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from clickhouse-connect>=0.5.7->chromadb) (4.3.2)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from fastapi>=0.85.1->chromadb) (0.27.0)\n",
      "Requirement already satisfied: coloredlogs in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
      "Requirement already satisfied: packaging in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (23.1)\n",
      "Requirement already satisfied: protobuf in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (4.23.3)\n",
      "Requirement already satisfied: sympy in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from pandas>=1.3->chromadb) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: monotonic>=1.5 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from requests>=2.28->chromadb) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from requests>=2.28->chromadb) (3.4)\n",
      "Requirement already satisfied: click>=7.0 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (8.1.3)\n",
      "Requirement already satisfied: h11>=0.8 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.5.0)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (6.0)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.17.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (11.0.3)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from starlette<0.28.0,>=0.27.0->fastapi>=0.85.1->chromadb) (3.7.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi>=0.85.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi>=0.85.1->chromadb) (1.1.1)\n",
      "Requirement already satisfied: tiktoken in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (0.4.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from tiktoken) (2023.6.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2023.5.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install unstructured\n",
    "!pip install chromadb\n",
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b40ddb5",
   "metadata": {},
   "source": [
    "这段代码是导入了 langchain 库中的一些模块和类，具体解释如下：\n",
    "\n",
    "1. `from langchain.document_loaders import DirectoryLoader`：从 langchain 库中导入 `DirectoryLoader` 类，用于从文件夹中加载文档。\n",
    "2. `from langchain.text_splitter import CharacterTextSplitter`：从 langchain 库中导入 `CharacterTextSplitter` 类，用于将文本分割成字符。\n",
    "3. `from langchain.vectorstores import Chroma`：从 langchain 库中导入 `Chroma` 类，用于计算音乐的 Chroma 特征向量。\n",
    "4. `from langchain.embeddings import OpenAIEmbeddings`：从 langchain 库中导入 `OpenAIEmbeddings` 类，用于获取 OpenAI 的预训练词向量。\n",
    "5. `from langchain import OpenAI, VectorDBQA`：从 langchain 库中导入 `OpenAI` 和 `VectorDBQA` 类。\n",
    "6. `from langchain.chains import RetrievalQA`：从 langchain 库中导入 `RetrievalQA` 类，用于实现检索式问答。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3a854f8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T05:45:09.262692Z",
     "start_time": "2023-06-28T05:45:09.260001Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain import OpenAI, VectorDBQA\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0bfbfd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T02:40:07.249197Z",
     "start_time": "2023-06-27T02:40:07.245711Z"
    }
   },
   "source": [
    "载入 `./Contents/` 文件中的 `.txt` 文件，并转换成 `document`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "229d6515",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T05:45:20.414135Z",
     "start_time": "2023-06-28T05:45:19.660286Z"
    }
   },
   "outputs": [],
   "source": [
    "loader = DirectoryLoader(path='./Contents/', glob='**/*.txt')\n",
    "document = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bac7f9f",
   "metadata": {},
   "source": [
    "初始化文本分割器，并分割文本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f87eaa91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T05:45:37.029229Z",
     "start_time": "2023-06-28T05:45:37.026433Z"
    }
   },
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=10)\n",
    "documents = text_splitter.split_documents(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9603d2",
   "metadata": {},
   "source": [
    "初始化 Open AI 的 Embedding 对象。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1f4d5c9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T05:45:39.299898Z",
     "start_time": "2023-06-28T05:45:39.297253Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcecedb",
   "metadata": {},
   "source": [
    "通过 Open AI 的 Embedding 对象，将分割好的文本做成一个个向量数据，放入向量数据库。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d803c8c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T05:45:52.655226Z",
     "start_time": "2023-06-28T05:45:47.496983Z"
    }
   },
   "outputs": [],
   "source": [
    "docsearch = Chroma.from_documents(documents, embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf36a07a",
   "metadata": {},
   "source": [
    "创建问答对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "400ae2b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T05:46:41.363037Z",
     "start_time": "2023-06-28T05:46:41.359631Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "QArobot = VectorDBQA.from_chain_type(llm=OpenAI(), chain_type='stuff', vectorstore=docsearch, \n",
    "                                     return_source_documents=False,\n",
    "                                     verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3709dc33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T05:47:44.103272Z",
     "start_time": "2023-06-28T05:47:41.215186Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': '本文的主人公是谁？他们在哪里？',\n",
       " 'result': ' The protagonists of this article are Fu Hongyuan, a PhD student from the class of 2022, and the members of the Major Railway Rock Burst Technology Research Group. They are at the construction site of a major railway project.'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 进行问答\n",
    "question = \"本文的主人公是谁？他们在哪里？\"\n",
    "result = QArobot({\"query\": question})\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c5f8fe",
   "metadata": {},
   "source": [
    "# <font color=red>项目5：基于持久知识库的问答机器人</font>\n",
    "\n",
    "项目4的embedding在导入数据后需要计算一次；重启这个python就要反复计算，效率就降低了。\n",
    "\n",
    "需要将本地文件转换成数据库，最好可以永久放在本地电脑上，这样重复加载时候就会快很多。\n",
    "\n",
    "chroma 是个本地的向量数据库，他提供的一个 `persist_directory` 来设置持久化目录进行持久化。读取时，只需要调取 `from_document` 方法加载即可。\n",
    "\n",
    "除此之外，还有：Pinecone 是一个在线的向量数据库。所以，我可以第一步依旧是注册，然后拿到对应的 api key。https://app.pinecone.io/ （不建议使用这个，需要付费）\n",
    "\n",
    "大部分代码与项目4类似。在此处就做持久化的实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f87d1d83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T05:48:19.057973Z",
     "start_time": "2023-06-28T05:48:18.243358Z"
    }
   },
   "outputs": [],
   "source": [
    "docsearch_persist = Chroma.from_documents(documents=documents, embedding=embedding, \n",
    "                                          persist_directory='./Contents/')  # 持久化标识\n",
    "docsearch_persist.persist()\n",
    "# 从持久库中加载数据\n",
    "docsearch_persist = Chroma(persist_directory='./Contents/', embedding_function=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "50c878f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T05:48:23.451455Z",
     "start_time": "2023-06-28T05:48:23.448321Z"
    }
   },
   "outputs": [],
   "source": [
    "QArobot = VectorDBQA.from_chain_type(llm=OpenAI(), chain_type='stuff', vectorstore=docsearch_persist, \n",
    "                                     return_source_documents=False,\n",
    "                                     verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1a60b78f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T05:48:27.006901Z",
     "start_time": "2023-06-28T05:48:24.763397Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': '本文中 He Benguo 做了什么？',\n",
       " 'result': ' He Benguo communicated with Fu Hongyuan in a timely manner, understood his living and research situation, and provided targeted guidance.'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 进行问答\n",
    "question = \"本文中 He Benguo 做了什么？\"\n",
    "result = QArobot({\"query\": question})\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be6c607",
   "metadata": {},
   "source": [
    "# <font color=red>项目6：使用GPT-3.5模型构建基于youtube网站的视频问答机器人</font>\n",
    "\n",
    "设置了这个机器人，在浏览youtube的一些课程的时候，走神了就可以问这个机器人让他得到答案。\n",
    "\n",
    "我猜基本原理是youtube有个自动生成字幕的功能，LangChain通过获取字幕内容来分析。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9fed1891",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T05:48:35.363084Z",
     "start_time": "2023-06-28T05:48:34.454078Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: youtube-transcript-api in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (0.6.1)\r\n",
      "Requirement already satisfied: requests in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from youtube-transcript-api) (2.31.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from requests->youtube-transcript-api) (3.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from requests->youtube-transcript-api) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from requests->youtube-transcript-api) (2.0.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/zjb/anaconda3/envs/gptnew/lib/python3.10/site-packages (from requests->youtube-transcript-api) (2023.5.7)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install youtube-transcript-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d8f2b313",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T05:49:03.304121Z",
     "start_time": "2023-06-28T05:49:03.300721Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import YoutubeLoader\n",
    "from langchain.text_splitter import TextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import ChatVectorDBChain, ConversationalRetrievalChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bfa91c",
   "metadata": {},
   "source": [
    "加载 Youtube 里面的视频！\n",
    "\n",
    "这里选用元强化学习 CBFinn 女士的一个 lecture 的视频～\n",
    "\n",
    "https://www.youtube.com/watch?v=c0vSwglRY4w\n",
    "\n",
    "(((Youtube 的广告是真的多。。。。。。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ee659765",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T05:49:28.048472Z",
     "start_time": "2023-06-28T05:49:26.710883Z"
    }
   },
   "outputs": [],
   "source": [
    "loader = YoutubeLoader.from_youtube_url(youtube_url='https://www.youtube.com/watch?v=c0vSwglRY4w')\n",
    "youtube_document = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1626e485",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T05:49:36.079112Z",
     "start_time": "2023-06-28T05:49:36.076845Z"
    }
   },
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "415e332b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T05:49:40.864806Z",
     "start_time": "2023-06-28T05:49:40.851657Z"
    }
   },
   "outputs": [],
   "source": [
    "youtube_documents = text_splitter.split_documents(youtube_document)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dc71e8",
   "metadata": {},
   "source": [
    "将 documents 放入向量数据库中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "33e8820b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T05:50:00.740571Z",
     "start_time": "2023-06-28T05:49:52.698337Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings()\n",
    "vector_database = Chroma.from_documents(youtube_documents, embedding)\n",
    "# 通过向量存储初始化检索器\n",
    "retriever = vector_database.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca317154",
   "metadata": {},
   "source": [
    "因为是对话机器人，所以要初始化对话模板。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fcac5f68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T05:51:02.838241Z",
     "start_time": "2023-06-28T05:51:02.836153Z"
    }
   },
   "outputs": [],
   "source": [
    "system_template = \"\"\"\n",
    "Use the following context to answer the user's question.\n",
    "If you don't know the answer, say you don't, don't try to make it up. And answer in Chinese.\n",
    "-----------\n",
    "{chat_history}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae37030",
   "metadata": {},
   "source": [
    "构建初始 messages 列表，这里可以理解为是 openai 传入的 messages 参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5fc89bbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T05:51:18.003888Z",
     "start_time": "2023-06-28T05:51:18.000231Z"
    }
   },
   "outputs": [],
   "source": [
    "messages = [SystemMessagePromptTemplate.from_template(system_template),\n",
    "           HumanMessagePromptTemplate.from_template(\"{question}\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f815efd9",
   "metadata": {},
   "source": [
    "初始化 prompt 对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "aa3837da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T05:51:29.939838Z",
     "start_time": "2023-06-28T05:51:29.937367Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dac12d1",
   "metadata": {},
   "source": [
    "开始构建智能对话机器人"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c1c597c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T05:52:11.093216Z",
     "start_time": "2023-06-28T05:52:11.089915Z"
    }
   },
   "outputs": [],
   "source": [
    "YoutubeQARobot = ConversationalRetrievalChain.from_llm(llm=ChatOpenAI(max_tokens=2048, temperature=0.5),\n",
    "                                                       retriever=retriever,\n",
    "                                                       condense_question_prompt=prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10c420f",
   "metadata": {},
   "source": [
    "开始进行对话～"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e83ead3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T05:57:52.621980Z",
     "start_time": "2023-06-28T05:57:08.980632Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "问题：你好！\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised ServiceUnavailableError: The server is overloaded or not ready yet..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好！有什么我可以帮助你的吗？\n",
      "问题：\n",
      "会话已经结束。\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "while True:\n",
    "    question = input(\"问题：\")\n",
    "    if question == '':\n",
    "        print(\"会话已经结束。\")\n",
    "        break\n",
    "    result = YoutubeQARobot(\n",
    "        {'question':question, 'chat_history':chat_history}\n",
    "    )\n",
    "    chat_history.append((question, result['answer']))\n",
    "    print(result['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cf7fc7",
   "metadata": {},
   "source": [
    "# <font color=red>项目7：执行多个大语言链</font>\n",
    "\n",
    "用于做更加多的工作～"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f250d8c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T05:58:49.412306Z",
     "start_time": "2023-06-28T05:58:49.408588Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import SimpleSequentialChain, LLMChain\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "66c87b87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T05:58:52.363686Z",
     "start_time": "2023-06-28T05:58:52.360940Z"
    }
   },
   "outputs": [],
   "source": [
    "llm_model = OpenAI(temperature=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d1ae1d",
   "metadata": {},
   "source": [
    "这个是任务完成的第一步，也就是一个chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c45ce381",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T05:59:26.873696Z",
     "start_time": "2023-06-28T05:59:26.871076Z"
    }
   },
   "outputs": [],
   "source": [
    "# location 链\n",
    "template = \"\"\"\n",
    "Your job is to come up with a classic dish from the area that the users suggests.\n",
    "\n",
    "% USER LOCATION\n",
    "{user_location}\n",
    "\n",
    "YOUR RESPONSE:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0768e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T07:14:44.360039Z",
     "start_time": "2023-06-27T07:14:44.347302Z"
    }
   },
   "source": [
    "第一个chain的模板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0c8560a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T05:59:28.061845Z",
     "start_time": "2023-06-28T05:59:28.059333Z"
    }
   },
   "outputs": [],
   "source": [
    "first_prompt_template = PromptTemplate(input_variables=['user_location'], template=template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f008d4c",
   "metadata": {},
   "source": [
    "构建第一个语言链任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3ff1ac34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T05:59:29.657209Z",
     "start_time": "2023-06-28T05:59:29.654757Z"
    }
   },
   "outputs": [],
   "source": [
    "first_chain = LLMChain(llm=llm_model, prompt=first_prompt_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9007b46",
   "metadata": {},
   "source": [
    "这个是任务完成的第二步，也就是第二个chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "76ca66a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T05:59:34.694284Z",
     "start_time": "2023-06-28T05:59:34.691272Z"
    }
   },
   "outputs": [],
   "source": [
    "# meal 链\n",
    "template = \"\"\"\n",
    "Given a meal, give a short and simple recipe on how to make that dish at home.\n",
    "\n",
    "% MEAL\n",
    "{user_meal}\n",
    "\n",
    "YOUR RESPONSE:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8b7437c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T05:59:49.971876Z",
     "start_time": "2023-06-28T05:59:49.969495Z"
    }
   },
   "outputs": [],
   "source": [
    "second_prompt_template = PromptTemplate(input_variables=['user_meal'], template=template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ab8df6",
   "metadata": {},
   "source": [
    "构建第二个chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0a196572",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T05:59:51.068954Z",
     "start_time": "2023-06-28T05:59:51.064820Z"
    }
   },
   "outputs": [],
   "source": [
    "second_chain = LLMChain(llm=llm_model, prompt=second_prompt_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9943a0",
   "metadata": {},
   "source": [
    "<font color=red>通过 SimpleSequentialChain 串联起来，第一个答案会被替换第二个中的user_meal，然后再进行询问</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bbc8fa11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T06:01:35.758732Z",
     "start_time": "2023-06-28T06:01:35.756504Z"
    }
   },
   "outputs": [],
   "source": [
    "overall_chain = SimpleSequentialChain(chains=[first_chain,second_chain],verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ed1f5cae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T06:02:10.117487Z",
     "start_time": "2023-06-28T06:02:02.831923Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Pad Thai Recipe                                                                                                    \n",
       "\n",
       "Ingredients:                                                                                                       \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>4 ounces dried rice noodles                                                                                     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>2 tablespoons vegetable oil                                                                                     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>1/2 cup diced firm tofu                                                                                         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>2 large eggs, lightly beaten                                                                                    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>1/4 cup chopped peanuts                                                                                         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>1 cup bean sprouts                                                                                              \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>2 tablespoons soy sauce                                                                                         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>2 tablespoons fish sauce                                                                                        \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>2 tablespoons brown sugar                                                                                       \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>2 tablespoons lime juice                                                                                        \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>1/4 teaspoon red pepper flakes (optional)                                                                       \n",
       "\n",
       "Instructions:                                                                                                      \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 1 </span>Bring a large pot of salted water to a boil over high heat. Add the noodles and cook until al dente, about 8    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>minutes. Drain and rinse with cold water.                                                                       \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 2 </span>Heat the oil in a wok or large skillet over high heat. Add the tofu and cook until lightly browned, about 5     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>minutes.                                                                                                        \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 3 </span>Push the tofu to the sides of the pan and pour the eggs into the center. Cook until the eggs are lightly        \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>scrambled, about 2 minutes.                                                                                     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 4 </span>Add the noodles, peanuts, bean sprouts, soy sauce, fish sauce, sugar, lime juice, and pepper flakes (if using)  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>to the pan. Stir everything together and cook until the noodles are hot, about 2 minutes.                       \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 5 </span>Serve                                                                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Pad Thai Recipe                                                                                                    \n",
       "\n",
       "Ingredients:                                                                                                       \n",
       "\n",
       "\u001b[1;33m • \u001b[0m4 ounces dried rice noodles                                                                                     \n",
       "\u001b[1;33m • \u001b[0m2 tablespoons vegetable oil                                                                                     \n",
       "\u001b[1;33m • \u001b[0m1/2 cup diced firm tofu                                                                                         \n",
       "\u001b[1;33m • \u001b[0m2 large eggs, lightly beaten                                                                                    \n",
       "\u001b[1;33m • \u001b[0m1/4 cup chopped peanuts                                                                                         \n",
       "\u001b[1;33m • \u001b[0m1 cup bean sprouts                                                                                              \n",
       "\u001b[1;33m • \u001b[0m2 tablespoons soy sauce                                                                                         \n",
       "\u001b[1;33m • \u001b[0m2 tablespoons fish sauce                                                                                        \n",
       "\u001b[1;33m • \u001b[0m2 tablespoons brown sugar                                                                                       \n",
       "\u001b[1;33m • \u001b[0m2 tablespoons lime juice                                                                                        \n",
       "\u001b[1;33m • \u001b[0m1/4 teaspoon red pepper flakes (optional)                                                                       \n",
       "\n",
       "Instructions:                                                                                                      \n",
       "\n",
       "\u001b[1;33m 1 \u001b[0mBring a large pot of salted water to a boil over high heat. Add the noodles and cook until al dente, about 8    \n",
       "\u001b[1;33m   \u001b[0mminutes. Drain and rinse with cold water.                                                                       \n",
       "\u001b[1;33m 2 \u001b[0mHeat the oil in a wok or large skillet over high heat. Add the tofu and cook until lightly browned, about 5     \n",
       "\u001b[1;33m   \u001b[0mminutes.                                                                                                        \n",
       "\u001b[1;33m 3 \u001b[0mPush the tofu to the sides of the pan and pour the eggs into the center. Cook until the eggs are lightly        \n",
       "\u001b[1;33m   \u001b[0mscrambled, about 2 minutes.                                                                                     \n",
       "\u001b[1;33m 4 \u001b[0mAdd the noodles, peanuts, bean sprouts, soy sauce, fish sauce, sugar, lime juice, and pepper flakes (if using)  \n",
       "\u001b[1;33m   \u001b[0mto the pan. Stir everything together and cook until the noodles are hot, about 2 minutes.                       \n",
       "\u001b[1;33m 5 \u001b[0mServe                                                                                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = overall_chain.run('Tailand')\n",
    "csl.print(Markdown(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384a6964",
   "metadata": {},
   "source": [
    "# <font color=red>项目8：结构化输出</font>\n",
    "\n",
    "这样做的好处是，可以给后续做软件、做深度学习模型提供更加便捷的方案～～"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "33bb0816",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T06:02:35.877484Z",
     "start_time": "2023-06-28T06:02:35.873788Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5212fa87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T06:02:37.663116Z",
     "start_time": "2023-06-28T06:02:37.659940Z"
    }
   },
   "outputs": [],
   "source": [
    "llm_model = OpenAI(model='text-davinci-003',\n",
    "                  max_tokens=2048,\n",
    "                  temperature=0.5,\n",
    "                  verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a58fac7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T06:02:55.619392Z",
     "start_time": "2023-06-28T06:02:55.616914Z"
    }
   },
   "outputs": [],
   "source": [
    "# 告诉他我们生成的内容需要哪些字段，每个字段类型式啥\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"bad_string\", description=\"This a poorly formatted user input string\"),\n",
    "    ResponseSchema(name=\"good_string\", description=\"This is your response, a reformatted response\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "da958979",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T06:03:02.798521Z",
     "start_time": "2023-06-28T06:03:02.794570Z"
    }
   },
   "outputs": [],
   "source": [
    "output_parsr = StructuredOutputParser.from_response_schemas(response_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "21af67c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T06:04:30.862489Z",
     "start_time": "2023-06-28T06:04:30.856940Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \n",
       "\"<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #000000\">json\" and \"</span>\":                                                                                                     \n",
       "\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">{</span><span style=\"background-color: #272822\">                                                                                                                  </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #f92672; text-decoration-color: #f92672; background-color: #272822\">\"bad_string\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">: </span><span style=\"color: #960050; text-decoration-color: #960050; background-color: #1e0010\">s</span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">tr</span><span style=\"color: #960050; text-decoration-color: #960050; background-color: #1e0010\">i</span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">n</span><span style=\"color: #960050; text-decoration-color: #960050; background-color: #1e0010\">g</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">  </span><span style=\"color: #75715e; text-decoration-color: #75715e; background-color: #272822\">// This a poorly formatted user input string</span><span style=\"background-color: #272822\">                                             </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #f92672; text-decoration-color: #f92672; background-color: #272822\">\"good_string\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">: </span><span style=\"color: #960050; text-decoration-color: #960050; background-color: #1e0010\">s</span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">tr</span><span style=\"color: #960050; text-decoration-color: #960050; background-color: #1e0010\">i</span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">n</span><span style=\"color: #960050; text-decoration-color: #960050; background-color: #1e0010\">g</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">  </span><span style=\"color: #75715e; text-decoration-color: #75715e; background-color: #272822\">// This is your response, a reformatted response</span><span style=\"background-color: #272822\">                                        </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">}</span><span style=\"background-color: #272822\">                                                                                                                  </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \n",
       "\"\u001b[97;40mjson\" and \"\u001b[0m\":                                                                                                     \n",
       "\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34m{\u001b[0m\u001b[48;2;39;40;34m                                                                                                                  \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;249;38;114;48;2;39;40;34m\"bad_string\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;150;0;80;48;2;30;0;16ms\u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mtr\u001b[0m\u001b[38;2;150;0;80;48;2;30;0;16mi\u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mn\u001b[0m\u001b[38;2;150;0;80;48;2;30;0;16mg\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m  \u001b[0m\u001b[38;2;117;113;94;48;2;39;40;34m// This a poorly formatted user input string\u001b[0m\u001b[48;2;39;40;34m                                             \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;249;38;114;48;2;39;40;34m\"good_string\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;150;0;80;48;2;30;0;16ms\u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mtr\u001b[0m\u001b[38;2;150;0;80;48;2;30;0;16mi\u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mn\u001b[0m\u001b[38;2;150;0;80;48;2;30;0;16mg\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m  \u001b[0m\u001b[38;2;117;113;94;48;2;39;40;34m// This is your response, a reformatted response\u001b[0m\u001b[48;2;39;40;34m                                        \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34m}\u001b[0m\u001b[48;2;39;40;34m                                                                                                                  \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "format_instructions = output_parsr.get_format_instructions()\n",
    "csl.print(Markdown(format_instructions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "95768597",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T06:05:39.265512Z",
     "start_time": "2023-06-28T06:05:39.263326Z"
    }
   },
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You will be given a poorly formatted string from a user.\n",
    "Reformat it and make sure all the words are spelled correctly\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "% USER INPUT:\n",
    "{user_input}\n",
    "\n",
    "YOUR RESPONSE:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "013c5ab8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T06:04:45.413835Z",
     "start_time": "2023-06-28T06:04:45.410454Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=['user_input'],\n",
    "    partial_variables={'format_instructions':format_instructions},\n",
    "    template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "40778bd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T06:04:48.033381Z",
     "start_time": "2023-06-28T06:04:48.030224Z"
    }
   },
   "outputs": [],
   "source": [
    "promptValue = prompt.format(user_input=\"welcom to califonya!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "56587b8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T06:05:19.047515Z",
     "start_time": "2023-06-28T06:05:17.445974Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">{</span><span style=\"background-color: #272822\">                                                                                                                  </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #f92672; text-decoration-color: #f92672; background-color: #272822\">\"bad_string\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">: </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"welcom to califonya!\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">                                                                          </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #f92672; text-decoration-color: #f92672; background-color: #272822\">\"good_string\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">: </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"Welcome to California!\"</span><span style=\"background-color: #272822\">                                                                        </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">}</span><span style=\"background-color: #272822\">                                                                                                                  </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;248;248;242;48;2;39;40;34m{\u001b[0m\u001b[48;2;39;40;34m                                                                                                                  \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;249;38;114;48;2;39;40;34m\"bad_string\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"welcom to califonya!\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                                                          \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;249;38;114;48;2;39;40;34m\"good_string\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"Welcome to California!\"\u001b[0m\u001b[48;2;39;40;34m                                                                        \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34m}\u001b[0m\u001b[48;2;39;40;34m                                                                                                                  \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm_output = llm_model(promptValue)\n",
    "csl.print(Markdown(llm_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5d0fa6",
   "metadata": {},
   "source": [
    "使用刚才初始化好的解析器解析 llm_output 字符串。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a86c0c06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T06:05:45.452479Z",
     "start_time": "2023-06-28T06:05:45.448319Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bad_string': 'welcom to califonya!', 'good_string': 'Welcome to California!'}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_result = output_parsr.parse(llm_output)\n",
    "total_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d081f4",
   "metadata": {},
   "source": [
    "当然，我们也可以用rich库打印我们的结果。因为结果已经是一个字典了，所以打印字典就行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b18b4b08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T06:05:46.617469Z",
     "start_time": "2023-06-28T06:05:46.600503Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'bad_string'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'welcom to califonya!'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'good_string'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Welcome to California!'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'bad_string'\u001b[0m: \u001b[32m'welcom to califonya!'\u001b[0m, \u001b[32m'good_string'\u001b[0m: \u001b[32m'Welcome to California!'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich import print\n",
    "print(total_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dd678b",
   "metadata": {},
   "source": [
    "# <font color=red>项目9：爬取网页并生成json格式数据</font>\n",
    "\n",
    "这样刷arxiv、IEEE上的论文就更快啦～～～"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "14e62dac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T06:05:48.995717Z",
     "start_time": "2023-06-28T06:05:48.992055Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMRequestsChain, LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "15359556",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T06:05:52.595758Z",
     "start_time": "2023-06-28T06:05:52.592651Z"
    }
   },
   "outputs": [],
   "source": [
    "llm_model = OpenAI(model='text-davinci-003',\n",
    "                  max_tokens=1800,\n",
    "                  temperature=1,\n",
    "                  verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8a1bee4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T06:05:53.954647Z",
     "start_time": "2023-06-28T06:05:53.951172Z"
    }
   },
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "在 >>> 和 <<< 之间是网页的返回的HTML内容。\n",
    "网页是Arxiv网站中关于相关主题的论文简介。\n",
    "请抽取参数请求的信息。\n",
    "\n",
    ">>> {requests_result} <<<\n",
    "请使用如下的JSON格式返回数据\n",
    "{{\n",
    "  \"title\":\"a\",\n",
    "  \"author\":\"b\",\n",
    "  \"abstract\":\"c\",\n",
    "}}\n",
    "Extracted:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b84ad0eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T06:05:59.084845Z",
     "start_time": "2023-06-28T06:05:59.080496Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(input_variables=['requests_result'], template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c4edefa3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T06:06:20.134329Z",
     "start_time": "2023-06-28T06:06:20.131849Z"
    }
   },
   "outputs": [],
   "source": [
    "chain = LLMRequestsChain(\n",
    "    llm_chain=LLMChain(llm=llm_model, prompt=prompt),\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1ebb9264",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T06:06:22.160702Z",
     "start_time": "2023-06-28T06:06:22.158536Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs = {\n",
    "  \"url\": \"https://arxiv.org/search/?query=EEG&searchtype=all&source=header\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1917a779",
   "metadata": {},
   "source": [
    "#### 使用小贴士\n",
    "\n",
    "Regarding `openai.error.InvalidRequestError: This is a chat model and not supported in the v1/completions endpoint`\n",
    "\n",
    "The code you posted above would work immediately if you change just one thing: `gpt-3.5-turbo` to `text-davinci-003`. \n",
    "\n",
    "This gives you an answer as to why you're getting this error. \n",
    "\n",
    "It's because you used the code that works with the `GPT-3` API endpoint, but wanted to use the `GPT-3.5` model (i.e., `gpt-3.5-turbo`). \n",
    "\n",
    "See model endpoint compatibility.\n",
    "\n",
    "https://platform.openai.com/docs/models/how-we-use-your-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e5031e9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T06:06:43.835713Z",
     "start_time": "2023-06-28T06:06:36.458020Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"title\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Sparse wavelet-based solutions for the M/EEG inverse problem\"</span>,\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"author\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Samy Mokhtari, Jean-Michel Badier, Christian G. Bénar, Bruno Torrésani\"</span>,\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"abstract\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"This paper is concerned with variational and Bayesian approaches to neuro-electromagnetic inverse </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">problems (EEG and MEG). The strong indeterminacy of these problems is tackled by introducing sparsity inducing </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">regularization/priors in a transformed domain, namely a spatial wavelet domain. Sparsity in the wavelet domain </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">allows to reach ''data compression'' in the cortical sources domain. Spatial wavelets defined on the mesh graph of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the triangulated cortical surface are used, in combination with sparse regression techniques, namely LASSO </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">regression or sparse Bayesian learning, to provide localized and compressed estimates for brain activity from </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">sensor data. Numerical results on simulated and real MEG data are provided, which outline the performances of the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">proposed approach in terms of localization.\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\u001b[32m\"title\"\u001b[0m: \u001b[32m\"Sparse wavelet-based solutions for the M/EEG inverse problem\"\u001b[0m,\n",
       "\u001b[32m\"author\"\u001b[0m: \u001b[32m\"Samy Mokhtari, Jean-Michel Badier, Christian G. Bénar, Bruno Torrésani\"\u001b[0m,\n",
       "\u001b[32m\"abstract\"\u001b[0m: \u001b[32m\"This paper is concerned with variational and Bayesian approaches to neuro-electromagnetic inverse \u001b[0m\n",
       "\u001b[32mproblems \u001b[0m\u001b[32m(\u001b[0m\u001b[32mEEG and MEG\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. The strong indeterminacy of these problems is tackled by introducing sparsity inducing \u001b[0m\n",
       "\u001b[32mregularization/priors in a transformed domain, namely a spatial wavelet domain. Sparsity in the wavelet domain \u001b[0m\n",
       "\u001b[32mallows to reach ''data compression'' in the cortical sources domain. Spatial wavelets defined on the mesh graph of \u001b[0m\n",
       "\u001b[32mthe triangulated cortical surface are used, in combination with sparse regression techniques, namely LASSO \u001b[0m\n",
       "\u001b[32mregression or sparse Bayesian learning, to provide localized and compressed estimates for brain activity from \u001b[0m\n",
       "\u001b[32msensor data. Numerical results on simulated and real MEG data are provided, which outline the performances of the \u001b[0m\n",
       "\u001b[32mproposed approach in terms of localization.\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = chain(inputs)\n",
    "print(response['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fc5ea4",
   "metadata": {},
   "source": [
    "我们可以优化一下，这样就能实现任意主题的爬取～～～"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cca88fc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T06:12:39.285033Z",
     "start_time": "2023-06-28T06:07:29.854666Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请输入你的关键词：category level pose estimation\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"title\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"GenPose: Generative Category-level Object Pose Estimation via Diffusion Models\"</span>,\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"author\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Jiyao Zhang, Mingdong Wu, Hao Dong\"</span>,\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"abstract\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Object pose estimation plays a vital role in embodied AI and computer vision, enabling intelligent </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">agents to comprehend and interact with their surroundings. Despite the practicality of category-level pose </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">estimation, current approaches encounter challenges with partially observed point clouds, known as the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">multihypothesis issue. In this study, we propose a novel solution by reframing category-level object pose </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">estimation as conditional generative modeling, departing from traditional point-to-point regression. Leveraging </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">score-based diffusion models, we estimate object poses by sampling candidates from the diffusion model and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">aggregating them through a two-step process: filtering out outliers via likelihood estimation and subsequently </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">mean-pooling the remaining candidates. To avoid the costly integration process when estimating the likelihood, we </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">introduce an alternative method that trains an energy-based model from the original score-based model, enabling </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">end-to-end likelihood estimation. Our approach achieves state-of-the-art performance on the REAL275 dataset, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">surpassing 50% and 60% on strict 5d2cm and 5d5cm metrics, respectively. Furthermore, our method demonstrates strong</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">generalizability to novel categories sharing similar symmetric properties without fine-tuning and can readily adapt</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">to object pose tracking tasks, yielding comparable results to the current state-of-the-art baselines.\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[32m\"title\"\u001b[0m: \u001b[32m\"GenPose: Generative Category-level Object Pose Estimation via Diffusion Models\"\u001b[0m,\n",
       "\u001b[32m\"author\"\u001b[0m: \u001b[32m\"Jiyao Zhang, Mingdong Wu, Hao Dong\"\u001b[0m,\n",
       "\u001b[32m\"abstract\"\u001b[0m: \u001b[32m\"Object pose estimation plays a vital role in embodied AI and computer vision, enabling intelligent \u001b[0m\n",
       "\u001b[32magents to comprehend and interact with their surroundings. Despite the practicality of category-level pose \u001b[0m\n",
       "\u001b[32mestimation, current approaches encounter challenges with partially observed point clouds, known as the \u001b[0m\n",
       "\u001b[32mmultihypothesis issue. In this study, we propose a novel solution by reframing category-level object pose \u001b[0m\n",
       "\u001b[32mestimation as conditional generative modeling, departing from traditional point-to-point regression. Leveraging \u001b[0m\n",
       "\u001b[32mscore-based diffusion models, we estimate object poses by sampling candidates from the diffusion model and \u001b[0m\n",
       "\u001b[32maggregating them through a two-step process: filtering out outliers via likelihood estimation and subsequently \u001b[0m\n",
       "\u001b[32mmean-pooling the remaining candidates. To avoid the costly integration process when estimating the likelihood, we \u001b[0m\n",
       "\u001b[32mintroduce an alternative method that trains an energy-based model from the original score-based model, enabling \u001b[0m\n",
       "\u001b[32mend-to-end likelihood estimation. Our approach achieves state-of-the-art performance on the REAL275 dataset, \u001b[0m\n",
       "\u001b[32msurpassing 50% and 60% on strict 5d2cm and 5d5cm metrics, respectively. Furthermore, our method demonstrates strong\u001b[0m\n",
       "\u001b[32mgeneralizability to novel categories sharing similar symmetric properties without fine-tuning and can readily adapt\u001b[0m\n",
       "\u001b[32mto object pose tracking tasks, yielding comparable results to the current state-of-the-art baselines.\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请输入你的关键词：SLAM\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">{</span>\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"title\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"MOVESe: MOVablE and Moving LiDAR Scene Segmentation with Improved Navigation in Seg-label free </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">settings\"</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"author\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Prashant Kumar, Onkar Susladkar, Dhruv Makwana, Anurag Mittal, Prem Kumar Kalra\"</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"abstract\"</span>: \"Accurate detection of movable and moving objects in LiDAR is of vital importance for navigation. \n",
       "Most existing works focus on extracting and removing moving objects during navigation. Movable objects like \n",
       "pedestrians, parked vehicles, etc. although static may move in the future. This leads to erroneous navigation and \n",
       "accidents. In such cases, it becomes necessary to detect potentially movable objects. To this end, we present a \n",
       "learning-based approach that segments movable and moving objects by generating static parts of scenes that are \n",
       "otherwise occluded. Our model performs superior to existing baselines on static LiDAR reconstructions using <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> \n",
       "datasets including a challenging sparse industrial dataset. We achieve this without the assistance of any \n",
       "segmentation labels because such labels might not always be available for less popular yet important settings like \n",
       "industrial environments. The non-movable static parts of the scene generated by our model are of vital importance \n",
       "for downstream navigation for SLAM. The movable objects detected by our model can be fed to a downstream 3D \n",
       "detector for aiding navigation. Though we do not use segmentation, we evaluate our method against navigation \n",
       "baselines that use it to remove dynamic objects for SLAM. Through extensive experiments on several datasets, we \n",
       "showcase that our model surpasses these baselines on navigation.”\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m{\u001b[0m\n",
       "  \u001b[32m\"title\"\u001b[0m: \u001b[32m\"MOVESe: MOVablE and Moving LiDAR Scene Segmentation with Improved Navigation in Seg-label free \u001b[0m\n",
       "\u001b[32msettings\"\u001b[0m,\n",
       "  \u001b[32m\"author\"\u001b[0m: \u001b[32m\"Prashant Kumar, Onkar Susladkar, Dhruv Makwana, Anurag Mittal, Prem Kumar Kalra\"\u001b[0m,\n",
       "  \u001b[32m\"abstract\"\u001b[0m: \"Accurate detection of movable and moving objects in LiDAR is of vital importance for navigation. \n",
       "Most existing works focus on extracting and removing moving objects during navigation. Movable objects like \n",
       "pedestrians, parked vehicles, etc. although static may move in the future. This leads to erroneous navigation and \n",
       "accidents. In such cases, it becomes necessary to detect potentially movable objects. To this end, we present a \n",
       "learning-based approach that segments movable and moving objects by generating static parts of scenes that are \n",
       "otherwise occluded. Our model performs superior to existing baselines on static LiDAR reconstructions using \u001b[1;36m3\u001b[0m \n",
       "datasets including a challenging sparse industrial dataset. We achieve this without the assistance of any \n",
       "segmentation labels because such labels might not always be available for less popular yet important settings like \n",
       "industrial environments. The non-movable static parts of the scene generated by our model are of vital importance \n",
       "for downstream navigation for SLAM. The movable objects detected by our model can be fed to a downstream 3D \n",
       "detector for aiding navigation. Though we do not use segmentation, we evaluate our method against navigation \n",
       "baselines that use it to remove dynamic objects for SLAM. Through extensive experiments on several datasets, we \n",
       "showcase that our model surpasses these baselines on navigation.”\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请输入你的关键词：segment\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"title\"</span>:<span style=\"color: #008000; text-decoration-color: #008000\">\"What a MESS: Multi-Domain Evaluation of Zero-Shot Semantic Segmentation\"</span>,\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"author\"</span>:<span style=\"color: #008000; text-decoration-color: #008000\">\"Benedikt Blumenstiel, Johannes Jakubik, Hilde Kühne, Michael Vössing\"</span>,\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"abstract\"</span>:<span style=\"color: #008000; text-decoration-color: #008000\">\"While semantic segmentation has seen tremendous improvements in the past, there is still significant </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">labeling efforts necessary and the problem of limited generalization to classes that have not been present during </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">training. To address this problem, zero-shot semantic segmentation makes use of large self-supervised </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">vision-language models, allowing zero-shot transfer to unseen classes.\"</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m{\u001b[0m\n",
       "\u001b[32m\"title\"\u001b[0m:\u001b[32m\"What a MESS: Multi-Domain Evaluation of Zero-Shot Semantic Segmentation\"\u001b[0m,\n",
       "\u001b[32m\"author\"\u001b[0m:\u001b[32m\"Benedikt Blumenstiel, Johannes Jakubik, Hilde Kühne, Michael Vössing\"\u001b[0m,\n",
       "\u001b[32m\"abstract\"\u001b[0m:\u001b[32m\"While semantic segmentation has seen tremendous improvements in the past, there is still significant \u001b[0m\n",
       "\u001b[32mlabeling efforts necessary and the problem of limited generalization to classes that have not been present during \u001b[0m\n",
       "\u001b[32mtraining. To address this problem, zero-shot semantic segmentation makes use of large self-supervised \u001b[0m\n",
       "\u001b[32mvision-language models, allowing zero-shot transfer to unseen classes.\"\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请输入你的关键词：\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">没有输入关键词，已退出！\n",
       "</pre>\n"
      ],
      "text/plain": [
       "没有输入关键词，已退出！\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "while True: \n",
    "    key_words_raw = input(\"请输入你的关键词：\")\n",
    "    if key_words_raw == '':\n",
    "        print(\"没有输入关键词，已退出！\")\n",
    "        break\n",
    "    key_words_raw = key_words_raw.split()\n",
    "    start = '?query='\n",
    "    end = '&searchtype=all&source=header'\n",
    "    for i in range(len(key_words_raw)):\n",
    "        if i != len(key_words_raw)-1:\n",
    "            start = start + key_words_raw[i]+'+'\n",
    "        else:\n",
    "            start += key_words_raw[i]\n",
    "    start += end\n",
    "    address = \"https://arxiv.org/search/\"+start\n",
    "\n",
    "\n",
    "    inputs = {\n",
    "      \"url\": address\n",
    "    }\n",
    "\n",
    "    response = chain(inputs)\n",
    "    print(response['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96b17d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T08:43:48.820235Z",
     "start_time": "2023-06-27T08:43:48.816773Z"
    }
   },
   "source": [
    "# <font color=red>项目10：自定义agent中所使用的工具</font>\n",
    "\n",
    "自定义工具里面有个比较有意思的地方，使用哪个工具的权重是**靠工具中描述内容**来实现的，和我们之前编程靠数值来控制权重完全不同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5ad4845b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T06:12:42.454562Z",
     "start_time": "2023-06-28T06:12:42.452065Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain import LLMMathChain, SerpAPIWrapper\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.agents import initialize_agent, Tool, AgentType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "78efa5f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T06:12:45.472796Z",
     "start_time": "2023-06-28T06:12:45.470236Z"
    }
   },
   "outputs": [],
   "source": [
    "llm = OpenAI(model='text-davinci-003',\n",
    "            temperature=1,\n",
    "            max_tokens=2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6119553d",
   "metadata": {},
   "source": [
    "初始化搜索链和计算链"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3337acf8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T06:12:58.898389Z",
     "start_time": "2023-06-28T06:12:58.896119Z"
    }
   },
   "outputs": [],
   "source": [
    "search = SerpAPIWrapper()\n",
    "llm_math = LLMMathChain.from_llm(llm=llm, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4640a8f8",
   "metadata": {},
   "source": [
    "创建一个功能列表，指明这个 agent 里面都有哪些可用工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4ab502a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T06:13:12.922228Z",
     "start_time": "2023-06-28T06:13:12.918961Z"
    }
   },
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name = \"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Calculator\",\n",
    "        func=llm_math.run,\n",
    "        description=\"useful for when you need to answer questions about math\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603cd885",
   "metadata": {},
   "source": [
    "初始化 agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "807b6bc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T06:13:21.278731Z",
     "start_time": "2023-06-28T06:13:21.276058Z"
    }
   },
   "outputs": [],
   "source": [
    "agent = initialize_agent(tools=tools,agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0ba5e6",
   "metadata": {},
   "source": [
    "最后就能执行 agent 啦～～"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c6ced65f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T06:15:28.235275Z",
     "start_time": "2023-06-28T06:15:24.718561Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Jay Chou is currently 39 years old and his age multiplied by 0.43 is 16.77.                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Jay Chou is currently 39 years old and his age multiplied by 0.43 is 16.77.                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = agent.run(\"周杰伦现在几岁？他的年龄乘以0.43是多少\")\n",
    "csl.print(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfb65b1",
   "metadata": {},
   "source": [
    "# <font color=red>项目11：能一直聊天的对话机器人</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "641822ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T06:15:38.440461Z",
     "start_time": "2023-06-28T06:15:38.437891Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "54f4ee13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T06:15:39.048239Z",
     "start_time": "2023-06-28T06:15:39.044898Z"
    }
   },
   "outputs": [],
   "source": [
    "chat_model = ChatOpenAI(temperature=1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaba0667",
   "metadata": {},
   "source": [
    "因为聊天的本质实际是”聊天记录+当前的会话“，因此需要整合聊天历史。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "23ac237d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T06:15:42.573422Z",
     "start_time": "2023-06-28T06:15:42.569618Z"
    }
   },
   "outputs": [],
   "source": [
    "chat_history = ChatMessageHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "93501562",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T06:15:48.416932Z",
     "start_time": "2023-06-28T06:15:48.414361Z"
    }
   },
   "outputs": [],
   "source": [
    "# 给 MessageHistory 对象添加对话内容\n",
    "chat_history.add_ai_message(\"你好！\")\n",
    "chat_history.add_user_message(\"中国的首都是哪里？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "945013d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T06:15:55.185667Z",
     "start_time": "2023-06-28T06:15:53.010719Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'中国的首都是北京。'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 执行对话\n",
    "ai_response = chat_model(chat_history.messages)\n",
    "ai_response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "697fc0a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T06:19:44.978400Z",
     "start_time": "2023-06-28T06:19:15.244817Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">机器人：你好！\n",
       "</pre>\n"
      ],
      "text/plain": [
       "机器人：你好！\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好！\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 16.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[127], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     10\u001b[0m chat_history\u001b[38;5;241m.\u001b[39madd_user_message(user_message)\n\u001b[0;32m---> 11\u001b[0m ai_response \u001b[38;5;241m=\u001b[39m \u001b[43mchat_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchat_history\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m ai_message \u001b[38;5;241m=\u001b[39m ai_response\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m机器人：\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mai_message)\n",
      "File \u001b[0;32m~/anaconda3/envs/gptnew/lib/python3.10/site-packages/langchain/chat_models/base.py:195\u001b[0m, in \u001b[0;36mBaseChatModel.__call__\u001b[0;34m(self, messages, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    190\u001b[0m     messages: List[BaseMessage],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    194\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m--> 195\u001b[0m     generation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(generation, ChatGeneration):\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/anaconda3/envs/gptnew/lib/python3.10/site-packages/langchain/chat_models/base.py:95\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     94\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e)\n\u001b[0;32m---> 95\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m     96\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n\u001b[1;32m     97\u001b[0m generations \u001b[38;5;241m=\u001b[39m [res\u001b[38;5;241m.\u001b[39mgenerations \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results]\n",
      "File \u001b[0;32m~/anaconda3/envs/gptnew/lib/python3.10/site-packages/langchain/chat_models/base.py:87\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m new_arg_supported \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     85\u001b[0m )\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 87\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     88\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(m, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     89\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m     90\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(m, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m messages\n\u001b[1;32m     92\u001b[0m     ]\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     94\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e)\n",
      "File \u001b[0;32m~/anaconda3/envs/gptnew/lib/python3.10/site-packages/langchain/chat_models/base.py:88\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     83\u001b[0m new_arg_supported \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     85\u001b[0m )\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     87\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m---> 88\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m     90\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(m, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m messages\n\u001b[1;32m     92\u001b[0m     ]\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     94\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e)\n",
      "File \u001b[0;32m~/anaconda3/envs/gptnew/lib/python3.10/site-packages/langchain/chat_models/openai.py:354\u001b[0m, in \u001b[0;36mChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    346\u001b[0m     message \u001b[38;5;241m=\u001b[39m _convert_dict_to_message(\n\u001b[1;32m    347\u001b[0m         {\n\u001b[1;32m    348\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: inner_completion,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    351\u001b[0m         }\n\u001b[1;32m    352\u001b[0m     )\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatResult(generations\u001b[38;5;241m=\u001b[39m[ChatGeneration(message\u001b[38;5;241m=\u001b[39mmessage)])\n\u001b[0;32m--> 354\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletion_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[0;32m~/anaconda3/envs/gptnew/lib/python3.10/site-packages/langchain/chat_models/openai.py:302\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_completion_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 302\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_completion_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/gptnew/lib/python3.10/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs: t\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: t\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/gptnew/lib/python3.10/site-packages/tenacity/__init__.py:389\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoSleep):\n\u001b[1;32m    388\u001b[0m     retry_state\u001b[38;5;241m.\u001b[39mprepare_for_next_attempt()\n\u001b[0;32m--> 389\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m do\n",
      "File \u001b[0;32m~/anaconda3/envs/gptnew/lib/python3.10/site-packages/tenacity/nap.py:31\u001b[0m, in \u001b[0;36msleep\u001b[0;34m(seconds)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msleep\u001b[39m(seconds: \u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03m    Sleep strategy that delays execution for a given number of seconds.\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;03m    This is the default strategy, and may be mocked out for unit testing.\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseconds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 执行多轮对话\n",
    "start_sentence = \"你好！\"\n",
    "chat_history.add_ai_message(start_sentence)\n",
    "print(\"机器人：\"+start_sentence)\n",
    "while True: \n",
    "    user_message = input()\n",
    "    if user_message == '':\n",
    "        print(\"没有输入关键词，已退出！\")\n",
    "        break\n",
    "    chat_history.add_user_message(user_message)\n",
    "    ai_response = chat_model(chat_history.messages)\n",
    "    ai_message = ai_response.content\n",
    "    print(\"机器人：\"+ai_message)\n",
    "    chat_history.add_ai_message(ai_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ab67f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gptnew",
   "language": "python",
   "name": "gptnew"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
